{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\n",
    "            \"InstaDeepAI/genomics-long-range-benchmark\",\n",
    "            task_name='bulk_rna_expression',\n",
    "            sequence_length=2048,\n",
    "            cache_dir='data/genomic_long_range',\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "\n",
    "all_seqs=test_dataset['sequence']\n",
    "all_labels=test_dataset['labels']\n",
    "all_Chromosome=test_dataset['chromosome']\n",
    "batch_size=1\n",
    "\n",
    "\n",
    "  \n",
    "from scipy.stats import pearsonr\n",
    "from scipy import stats\n",
    "\n",
    "def spearmanr(logits,y):\n",
    "    #compute spearmanr correlation for each class\n",
    "    output={}\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    y = y.detach().cpu().numpy()\n",
    "    metrices = []\n",
    "    for i in range(logits.shape[0]):\n",
    "        spearmanrs = stats.spearmanr(logits[i, :], y[i, :])[0]\n",
    "        metrices.append(spearmanrs)\n",
    "    spearmanrs=np.nanmean(metrices,axis=0)\n",
    "    output['spearmanr']=spearmanrs\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearmanr(logits,y):\n",
    "    #compute spearmanr correlation for each class\n",
    "    output={}\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    y = y.detach().cpu().numpy()\n",
    "    metrices = []\n",
    "    for i in range(logits.shape[1]):\n",
    "        spearmanrs = stats.spearmanr(logits[:, i], y[:, i])[0]\n",
    "        metrices.append(spearmanrs)\n",
    "    spearmanrs=np.nanmean(metrices,axis=0)\n",
    "    output['spearmanr']=spearmanrs\n",
    "    \n",
    "    return output\n",
    "\n",
    "def mse(logits,y):\n",
    "    #compute mse for each class\n",
    "    output={}\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    y = y.detach().cpu().numpy()\n",
    "    metrices = []\n",
    "    for i in range(logits.shape[0]):\n",
    "        mse = np.mean((logits[i, :] - y[i, :]) ** 2)\n",
    "        metrices.append(mse)\n",
    "    mse=np.nanmean(metrices,axis=0)\n",
    "    output['mse']=mse\n",
    "\n",
    "    return output\n",
    "\n",
    "def R2(logits,y):\n",
    "    from sklearn.metrics import r2_score\n",
    "    #compute R2 for each class\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    y = y.detach().cpu().numpy()\n",
    "    metrices = []\n",
    "    for i in range(logits.shape[1]):\n",
    "        r2s = r2_score(y[:, i], logits[:, i])\n",
    "        metrices.append(r2s)\n",
    "    r2s=np.nanmean(metrices,axis=0)\n",
    "    return r2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "from torch import nn\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "state_dict='weight/hyenadna/hyenadna-large-1m-seqlen'\n",
    "d_model=256\n",
    "max_length=2048\n",
    "\n",
    "class hyena_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(hyena_model, self).__init__()\n",
    "        self.backbone=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "        self.output_transform = nn.Linear(d_model, 218)\n",
    "        self.linear = nn.Linear(2048,1)\n",
    "        # self.final_pointwise = nn.Sequential(\n",
    "        #     Rearrange('b n d -> b d n'),\n",
    "        #     ConvBlock(d_model, d_model*2, 1),\n",
    "        #     Rearrange('b d n -> b n d'),\n",
    "        #     GELU()\n",
    "        # )\n",
    "        \n",
    "        self.activation=nn.Softplus()\n",
    "    \n",
    "    def forward(self,input_ids,mask=None):\n",
    "        hidden_state=self.backbone(input_ids).last_hidden_state\n",
    "        if mask is None:\n",
    "                restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[..., -1:, :]           \n",
    "        else:\n",
    "                # sum masks\n",
    "                mask_sums = torch.sum(mask, dim=-1).squeeze() - 1  # for 0 indexing\n",
    "\n",
    "                # convert mask_sums to dtype int\n",
    "                mask_sums = mask_sums.type(torch.int64)\n",
    "\n",
    "                restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[torch.arange(x.size(0)), mask_sums, :].unsqueeze(1)  # need to keep original shape\n",
    "        \n",
    "        # hidden_state= (torch.cumsum(hidden_state, dim=-2)\n",
    "        #             / torch.arange(\n",
    "        #                 1, 1 + hidden_state.size(-2), device=hidden_state\n",
    "        #                 .device, dtype=hidden_state.dtype\n",
    "        #             ).unsqueeze(-1)\n",
    "        #         )[..., -1:, :]    \n",
    "        hidden_state=restrict(hidden_state)       \n",
    "        hidden_state = self.output_transform(hidden_state)\n",
    "        output = hidden_state.squeeze(1)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "checkpoint=torch.load('outputs/2024-05-09/04-54-29-787887/checkpoints/val/spearmanr.ckpt')['state_dict']\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.\"\n",
    "        )\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.\"\n",
    "        )\n",
    "hyena=hyena_model().to('cuda')\n",
    "hyena.load_state_dict(checkpoint,strict=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    state_dict='weight/hyenadna/hyenadna-large-1m-seqlen'\n",
    "    hyena_tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "    \n",
    "\n",
    "    target_list=[]\n",
    "    seq_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "        sequence_encoded=hyena_tokenizer(all_seqs[i],\n",
    "                            add_special_tokens= False,  # this is what controls adding eos\n",
    "                            padding=\"max_length\",\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                        )\n",
    "        seq_ids=sequence_encoded['input_ids']\n",
    "        seq_ids = torch.LongTensor(seq_ids)\n",
    "        target = all_labels[i][:1000]\n",
    "        \n",
    "        seqs=torch.reshape(seq_ids,(1,max_length)).to('cuda')\n",
    "        target_list.append(target)\n",
    "        \n",
    "        out1=hyena(seqs)\n",
    "        out1_hyena=out1.squeeze(1).squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        seq_list.append(out1_hyena)\n",
    "        seq_list_numpy_hyena=np.array(seq_list)\n",
    "\n",
    "        target_list_numpy=np.array(target_list)\n",
    "        seq_list_tensor=torch.FloatTensor(seq_list_numpy_hyena)\n",
    "        target_list_tensor=torch.FloatTensor(target_list_numpy)\n",
    "        #calculate the \n",
    "        if i>=1:\n",
    "            \n",
    "            \n",
    "            \n",
    "            spearmanr_value=R2(seq_list_tensor,target_list_tensor)\n",
    "            print('R2:',spearmanr_value)\n",
    "            spearmanr_value=spearmanr(seq_list_tensor,target_list_tensor)\n",
    "            print('Pearsonr:',spearmanr_value)\n",
    "            mse_out=mse(seq_list_tensor,target_list_tensor)\n",
    "            print('mse:',mse_out)\n",
    "\n",
    "#plot the bar plot of the pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "from torch import nn\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "\n",
    "max_length=2048\n",
    "state_dict='weight/dnabert2'\n",
    "d_model=768\n",
    "class bert2_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert2_model, self).__init__()\n",
    "        self.backbone=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "        self.output_transform = nn.Linear(d_model, 218)\n",
    "        self.linear = nn.Linear(2048,1)\n",
    "        # self.final_pointwise = nn.Sequential(\n",
    "        #     Rearrange('b n d -> b d n'),\n",
    "        #     ConvBlock(d_model, d_model*2, 1),\n",
    "        #     Rearrange('b d n -> b n d'),\n",
    "        #     GELU()\n",
    "        # )\n",
    "        \n",
    "        self.activation=nn.Softplus()\n",
    "    \n",
    "    def forward(self,input_ids,mask=None,encoder_attention_mask=None):\n",
    "        hidden_state=self.backbone(input_ids=seqs,attention_mask=mask,encoder_attention_mask=encoder_attention_mask,export_hidden_states=True)[0]\n",
    "        if mask is None:\n",
    "                restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[..., -1:, :]           \n",
    "        else:\n",
    "                # sum masks\n",
    "                mask_sums = torch.sum(mask, dim=-1).squeeze() - 1  # for 0 indexing\n",
    "\n",
    "                # convert mask_sums to dtype int\n",
    "                mask_sums = mask_sums.type(torch.int64)\n",
    "\n",
    "                restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[torch.arange(x.size(0)), mask_sums, :].unsqueeze(1)  # need to keep original shape\n",
    "        # hidden_state=self.linear(hidden_state.permute(0,2,1)).permute(0,2,1)\n",
    "        hidden_state=restrict(hidden_state)\n",
    "        # hidden_state = self.final_pointwise(hidden_state)\n",
    "        hidden_state = self.output_transform(hidden_state)\n",
    "        hidden_state=hidden_state.squeeze(-1)\n",
    "        output = hidden_state.squeeze(1)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "checkpoint=torch.load('outputs/2024-05-08/16-58-19-542915/checkpoints/val/spearmanr.ckpt')['state_dict']\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.\"\n",
    "        )\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.\"\n",
    "        )\n",
    "bert2=bert2_model().to('cuda')\n",
    "bert2.load_state_dict(checkpoint,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    bert2_tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "    \n",
    "\n",
    "    target_list=[]\n",
    "    seq_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "        sequence_encoded=bert2_tokenizer(all_seqs[i],\n",
    "                            add_special_tokens= False,  # this is what controls adding eos\n",
    "                            padding=\"max_length\",\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                        )\n",
    "        seq_ids=sequence_encoded['input_ids']\n",
    "        attention_mask=torch.BoolTensor(sequence_encoded['attention_mask']).int()\n",
    "        seq_ids = torch.LongTensor(seq_ids)\n",
    "        target = all_labels[i][:1000]\n",
    "        \n",
    "        seqs=torch.reshape(seq_ids,(1,max_length)).to('cuda')\n",
    "        attention_mask=torch.reshape(attention_mask,(1,max_length)).to('cuda')\n",
    "        target_list.append(target)\n",
    "        \n",
    "        out1=bert2(seqs,mask=attention_mask,encoder_attention_mask=attention_mask)\n",
    "        out1_bert2=out1.squeeze(1).squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        seq_list.append(out1_bert2)\n",
    "        seq_list_numpy_bert2=np.array(seq_list)\n",
    "\n",
    "        target_list_numpy=np.array(target_list)\n",
    "        seq_list_tensor=torch.FloatTensor(seq_list_numpy_bert2)\n",
    "        target_list_tensor=torch.FloatTensor(target_list_numpy)\n",
    "        #calculate the \n",
    "            \n",
    "            \n",
    "        if i>1:\n",
    "            spearmanr_value=R2(seq_list_tensor,target_list_tensor)\n",
    "            print('R2:',spearmanr_value)\n",
    "            spearmanr_value=spearmanr(seq_list_tensor,target_list_tensor)\n",
    "            print('Pearsonr:',spearmanr_value)\n",
    "            mse_out=mse(seq_list_tensor,target_list_tensor)\n",
    "            print(mse_out)\n",
    "\n",
    "#plot the bar plot of the pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "from torch import nn\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "\n",
    "max_length=2048\n",
    "state_dict='weight/genalm/gena-lm-bigbird-base-t2t'\n",
    "d_model=768\n",
    "class genalm_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(genalm_model, self).__init__()\n",
    "        self.backbone=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "        self.output_transform = nn.Linear(d_model, 218)\n",
    "        self.linear = nn.Linear(2048,1)\n",
    "        # self.final_pointwise = nn.Sequential(\n",
    "        #     Rearrange('b n d -> b d n'),\n",
    "        #     ConvBlock(d_model, d_model*2, 1),\n",
    "        #     Rearrange('b d n -> b n d'),\n",
    "        #     GELU()\n",
    "        # )\n",
    "        \n",
    "        self.activation=nn.Softplus()\n",
    "    \n",
    "    def forward(self,input_ids,mask=None,encoder_attention_mask=None):\n",
    "        hidden_state=self.backbone(input_ids=seqs, attention_mask=mask, encoder_attention_mask=encoder_attention_mask,output_hidden_states=True,).hidden_states[-1]\n",
    "        if mask is None:\n",
    "                restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[..., -1:, :]           \n",
    "        else:\n",
    "                # sum masks\n",
    "                mask_sums = torch.sum(mask, dim=-1).squeeze() - 1  # for 0 indexing\n",
    "\n",
    "                # convert mask_sums to dtype int\n",
    "                mask_sums = mask_sums.type(torch.int64)\n",
    "\n",
    "                restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[torch.arange(x.size(0)), mask_sums, :].unsqueeze(1)  # need to keep original shape\n",
    "        # hidden_state=self.linear(hidden_state.permute(0,2,1)).permute(0,2,1)\n",
    "        hidden_state=restrict(hidden_state)\n",
    "        # hidden_state = self.final_pointwise(hidden_state)\n",
    "        hidden_state = self.output_transform(hidden_state)\n",
    "        hidden_state=hidden_state.squeeze(-1)\n",
    "        output = hidden_state.squeeze(1)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "checkpoint=torch.load('/outputs/2024-05-08/18-52-56-671812/checkpoints/val/spearmanr.ckpt')['state_dict']\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.\"\n",
    "        )\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.\"\n",
    "        )\n",
    "genalm=genalm_model().to('cuda')\n",
    "genalm.load_state_dict(checkpoint,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    genalm_tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "    \n",
    "\n",
    "    target_list=[]\n",
    "    seq_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "        sequence_encoded=genalm_tokenizer(all_seqs[i],\n",
    "                            add_special_tokens= False,  # this is what controls adding eos\n",
    "                            padding=\"max_length\",\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                        )\n",
    "        seq_ids=sequence_encoded['input_ids']\n",
    "        attention_mask=torch.BoolTensor(sequence_encoded['attention_mask']).int()\n",
    "        seq_ids = torch.LongTensor(seq_ids)\n",
    "        target = all_labels[i][:1000]\n",
    "        \n",
    "        seqs=torch.reshape(seq_ids,(1,max_length)).to('cuda')\n",
    "        attention_mask=torch.reshape(attention_mask,(1,max_length)).to('cuda')\n",
    "        target_list.append(target)\n",
    "        \n",
    "        out1=genalm(seqs,mask=attention_mask,encoder_attention_mask=attention_mask)\n",
    "        out1_genalm=out1.squeeze(1).squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        seq_list.append(out1_genalm)\n",
    "        seq_list_numpy_genalm=np.array(seq_list)\n",
    "\n",
    "        target_list_numpy=np.array(target_list)\n",
    "        seq_list_tensor=torch.FloatTensor(seq_list_numpy_genalm)\n",
    "        target_list_tensor=torch.FloatTensor(target_list_numpy)\n",
    "        #calculate the \n",
    "            \n",
    "            \n",
    "        if i>1:\n",
    "            spearmanr_value=R2(seq_list_tensor,target_list_tensor)\n",
    "            print('R2:',spearmanr_value)\n",
    "            spearmanr_value=spearmanr(seq_list_tensor,target_list_tensor)\n",
    "            print('Pearsonr:',spearmanr_value)\n",
    "            mse_out=mse(seq_list_tensor,target_list_tensor)\n",
    "            print('mse:',mse_out)\n",
    "\n",
    "#plot the bar plot of the pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "from torch import nn\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "\n",
    "max_length=2048\n",
    "state_dict='mamba/caduceus-ph_seqlen-131k_d_model-256_n_layer-16'\n",
    "d_model=256\n",
    "class mamba_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mamba_model, self).__init__()\n",
    "        self.backbone=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "        self.output_transform = nn.Linear(d_model, 218)\n",
    "        self.linear = nn.Linear(2048,1)\n",
    "        # self.final_pointwise = nn.Sequential(\n",
    "        #     Rearrange('b n d -> b d n'),\n",
    "        #     ConvBlock(d_model, d_model*2, 1),\n",
    "        #     Rearrange('b d n -> b n d'),\n",
    "        #     GELU()\n",
    "        # )\n",
    "        \n",
    "        self.activation=nn.Softplus()\n",
    "    \n",
    "    def forward(self,input_ids,mask=None):\n",
    "        hidden_state=self.backbone(input_ids=seqs, output_hidden_states=True,).last_hidden_state\n",
    "\n",
    "        if mask is None:\n",
    "                restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[..., -1:, :]           \n",
    "        else:\n",
    "                # sum masks\n",
    "                mask_sums = torch.sum(mask, dim=-1).squeeze() - 1  # for 0 indexing\n",
    "\n",
    "                # convert mask_sums to dtype int\n",
    "                mask_sums = mask_sums.type(torch.int64)\n",
    "\n",
    "                restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[torch.arange(x.size(0)), mask_sums, :].unsqueeze(1)  # need to keep original shape\n",
    "        # hidden_state=self.linear(hidden_state.permute(0,2,1)).permute(0,2,1)\n",
    "        # hidden_state = self.final_pointwise(hidden_state)\n",
    "        hidden_state=restrict(hidden_state)\n",
    "        hidden_state = self.output_transform(hidden_state)\n",
    "        output = hidden_state.squeeze(1)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "checkpoint=torch.load('outputs/2024-05-09/05-38-26-912516/checkpoints/val/spearmanr.ckpt')['state_dict']\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.\"\n",
    "        )\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.\"\n",
    "        )\n",
    "mamba=mamba_model().to('cuda')\n",
    "mamba.load_state_dict(checkpoint,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    mamba_tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "    \n",
    "\n",
    "    target_list=[]\n",
    "    seq_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "        sequence_encoded=mamba_tokenizer(all_seqs[i],\n",
    "                            add_special_tokens= False,  # this is what controls adding eos\n",
    "                            padding=\"max_length\",\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                        )\n",
    "        seq_ids=sequence_encoded['input_ids']\n",
    "        seq_ids = torch.LongTensor(seq_ids)\n",
    "        target = all_labels[i][:1000]\n",
    "        \n",
    "        seqs=torch.reshape(seq_ids,(1,max_length)).to('cuda')\n",
    "        target_list.append(target)\n",
    "        \n",
    "        out1=mamba(seqs)\n",
    "        out1_mamba=out1.squeeze(1).squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        seq_list.append(out1_mamba)\n",
    "        seq_list_numpy_mamba=np.array(seq_list)\n",
    "\n",
    "        target_list_numpy=np.array(target_list)\n",
    "        seq_list_tensor=torch.FloatTensor(seq_list_numpy_mamba)\n",
    "        target_list_tensor=torch.FloatTensor(target_list_numpy)\n",
    "        #calculate the \n",
    "            \n",
    "            \n",
    "        if i>1:\n",
    "            spearmanr_value=R2(seq_list_tensor,target_list_tensor)\n",
    "            print('R2:',spearmanr_value)\n",
    "            spearmanr_value=spearmanr(seq_list_tensor,target_list_tensor)\n",
    "            print('Pearsonr:',spearmanr_value)\n",
    "            mse_out=mse(seq_list_tensor,target_list_tensor)\n",
    "            print('mse:',mse_out)\n",
    "\n",
    "#plot the bar plot of the pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel,AutoModelForMaskedLM\n",
    "from torch import nn\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "\n",
    "max_length=2048\n",
    "state_dict='/weight/nt/nucleotide-transformer-v2-500m-multi-species'\n",
    "d_model=1024\n",
    "class nt_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(nt_model, self).__init__()\n",
    "        self.backbone=AutoModelForMaskedLM.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "        self.output_transform = nn.Linear(d_model, 218)\n",
    "        self.linear = nn.Linear(2048,1)\n",
    "        # self.final_pointwise = nn.Sequential(\n",
    "        #     Rearrange('b n d -> b d n'),\n",
    "        #     ConvBlock(d_model, d_model*2, 1),\n",
    "        #     Rearrange('b d n -> b n d'),\n",
    "        #     GELU()\n",
    "        # )\n",
    "        \n",
    "        self.activation=nn.Softplus()\n",
    "    \n",
    "    def forward(self,input_ids,mask=None,encoder_attention_mask=None):\n",
    "        hidden_state=self.backbone(input_ids=seqs,attention_mask=mask,encoder_attention_mask=encoder_attention_mask,output_hidden_states=True)['hidden_states'][-1]\n",
    "        # hidden_state=self.linear(hidden_state.permute(0,2,1)).permute(0,2,1)\n",
    "        # hidden_state = self.final_pointwise(hidden_state)\n",
    "        if mask is None:\n",
    "                restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[..., -1:, :]           \n",
    "        else:\n",
    "                # sum masks\n",
    "                mask_sums = torch.sum(mask, dim=-1).squeeze() - 1  # for 0 indexing\n",
    "\n",
    "                # convert mask_sums to dtype int\n",
    "                mask_sums = mask_sums.type(torch.int64)\n",
    "\n",
    "                restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[torch.arange(x.size(0)), mask_sums, :].unsqueeze(1)  # need to keep original shape\n",
    "        # hidden_state=self.linear(hidden_state.permute(0,2,1)).permute(0,2,1)\n",
    "        hidden_state=restrict(hidden_state)\n",
    "        # hidden_state = self.final_pointwise(hidden_state)\n",
    "        hidden_state = self.output_transform(hidden_state)\n",
    "        hidden_state=hidden_state.squeeze(-1)\n",
    "        output = hidden_state.squeeze(1)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "checkpoint=torch.load('/outputs/2024-05-08/23-40-54-669800/checkpoints/val/spearmanr.ckpt')['state_dict']\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.\"\n",
    "        )\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.\"\n",
    "        )\n",
    "nt=nt_model().to('cuda')\n",
    "nt.load_state_dict(checkpoint,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    nt_tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "    \n",
    "\n",
    "    target_list=[]\n",
    "    seq_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "        sequence_encoded=nt_tokenizer(all_seqs[i],\n",
    "                            add_special_tokens= False,  # this is what controls adding eos\n",
    "                            padding=\"max_length\",\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                        )\n",
    "        seq_ids=sequence_encoded['input_ids']\n",
    "        attention_mask=torch.BoolTensor(sequence_encoded['attention_mask']).int()\n",
    "        seq_ids = torch.LongTensor(seq_ids)\n",
    "        target = all_labels[i][:1000]\n",
    "        \n",
    "        seqs=torch.reshape(seq_ids,(1,max_length)).to('cuda')\n",
    "        attention_mask=torch.reshape(attention_mask,(1,max_length)).to('cuda')\n",
    "        target_list.append(target)\n",
    "        \n",
    "        out1=nt(seqs,mask=attention_mask,encoder_attention_mask=attention_mask)\n",
    "        out1_nt=out1.squeeze(1).squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        seq_list.append(out1_nt)\n",
    "        seq_list_numpy_nt=np.array(seq_list)\n",
    "\n",
    "        target_list_numpy=np.array(target_list)\n",
    "        seq_list_tensor=torch.FloatTensor(seq_list_numpy_nt)\n",
    "        target_list_tensor=torch.FloatTensor(target_list_numpy)\n",
    "        #calculate the \n",
    "            \n",
    "            \n",
    "        if i>1:\n",
    "            spearmanr_value=R2(seq_list_tensor,target_list_tensor)\n",
    "            print('R2:',spearmanr_value)\n",
    "            spearmanr_value=spearmanr(seq_list_tensor,target_list_tensor)\n",
    "            print('Pearsonr:',spearmanr_value)\n",
    "            mse_out=mse(seq_list_tensor,target_list_tensor)\n",
    "            print('mse:',mse_out)\n",
    "\n",
    "#plot the bar plot of the pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel,AutoModelForMaskedLM\n",
    "from torch import nn\n",
    "from einops.layers.torch import Rearrange\n",
    "import sys\n",
    "\n",
    "from src.models.sequence.Enformer import Enformer\n",
    "max_length=2048\n",
    "d_model=3072\n",
    "class Enformer_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Enformer_model, self).__init__()\n",
    "        self.backbone=Enformer.from_hparams().to('cuda')\n",
    "        self.output_transform = nn.Linear(d_model, 218)\n",
    "        # self.final_pointwise = nn.Sequential(\n",
    "        #     Rearrange('b n d -> b d n'),\n",
    "        #     ConvBlock(d_model, d_model*2, 1),\n",
    "        #     Rearrange('b d n -> b n d'),\n",
    "        #     GELU()\n",
    "        # )\n",
    "        \n",
    "        self.activation=nn.Softplus()\n",
    "    \n",
    "    def forward(self,input_ids,mask=None,encoder_attention_mask=None):\n",
    "        hidden_state=self.backbone(input_ids)\n",
    "        # hidden_state=self.linear(hidden_state.permute(0,2,1)).permute(0,2,1)\n",
    "        # hidden_state = self.final_pointwise(hidden_state)\n",
    "        if mask is None:\n",
    "                restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[..., -1:, :]           \n",
    "        else:\n",
    "                # sum masks\n",
    "                mask_sums = torch.sum(mask, dim=-1).squeeze() - 1  # for 0 indexing\n",
    "\n",
    "                # convert mask_sums to dtype int\n",
    "                mask_sums = mask_sums.type(torch.int64)\n",
    "\n",
    "                restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[torch.arange(x.size(0)), mask_sums, :].unsqueeze(1)  # need to keep original shape\n",
    "        # hidden_state=self.linear(hidden_state.permute(0,2,1)).permute(0,2,1)\n",
    "        hidden_state=restrict(hidden_state)\n",
    "        # hidden_state = self.final_pointwise(hidden_state)\n",
    "        hidden_state = self.output_transform(hidden_state)\n",
    "        hidden_state=hidden_state.squeeze(-1)\n",
    "        output = hidden_state.squeeze(1)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "checkpoint=torch.load('outputs/2024-05-19/15-20-13-069602/checkpoints/val/spearmanr.ckpt')['state_dict']\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.\"\n",
    "        )\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.\"\n",
    "        )\n",
    "Enformer=Enformer_model().to('cuda')\n",
    "Enformer.load_state_dict(checkpoint,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def genomic_to_one_hot(genomic_sequence):\n",
    "        mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "        one_hot = np.zeros((len(genomic_sequence), 4))\n",
    "        for i, base in enumerate(genomic_sequence):\n",
    "            if base in mapping:\n",
    "                one_hot[i, mapping[base]] = 1\n",
    "            else:\n",
    "                # 如果碱基不是A、C、G、T或N，可以选择将其编码为全零向量或者平均分配概率\n",
    "                one_hot[i, :] = 0.25  # 或者使用 np.full((5,), 0.2) 平均分配概率\n",
    "        return one_hot\n",
    "with torch.no_grad():\n",
    "    \n",
    "\n",
    "    target_list=[]\n",
    "    seq_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "        seq = genomic_to_one_hot(all_seqs[i])[:max_length]\n",
    "        seq_ids = torch.from_numpy(seq).float().to('cuda')\n",
    "        target = all_labels[i][:1000]\n",
    "        \n",
    "        seqs=torch.reshape(seq_ids,(1,max_length,4)).to('cuda')\n",
    "        target_list.append(target)\n",
    "        \n",
    "        out1=Enformer(seqs)\n",
    "        out1_enformer=out1.squeeze(1).squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        seq_list.append(out1_enformer)\n",
    "        seq_list_numpy_enformer=np.array(seq_list)\n",
    "\n",
    "        target_list_numpy=np.array(target_list)\n",
    "        seq_list_tensor=torch.FloatTensor(seq_list_numpy_enformer)\n",
    "        target_list_tensor=torch.FloatTensor(target_list_numpy)\n",
    "        #calculate the \n",
    "            \n",
    "            \n",
    "        if i>1:\n",
    "            spearmanr_value=R2(seq_list_tensor,target_list_tensor)\n",
    "            print('R2:',spearmanr_value)\n",
    "            spearmanr_value=spearmanr(seq_list_tensor,target_list_tensor)\n",
    "            print('Pearsonr:',spearmanr_value)\n",
    "            mse_out=mse(seq_list_tensor,target_list_tensor)\n",
    "            print('mse:',mse_out)\n",
    "\n",
    "#plot the bar plot of the pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(range(len(seq_list_numpy[:,0])), seq_list_numpy[:,0], color='blue')\n",
    "plt.bar(range(len(seq_list_numpy_nt)), seq_list_numpy_nt[:,0], color='red')\n",
    "print(np.max(target_list_numpy))\n",
    "print(np.min(target_list_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(range(len(target_list_numpy)), target_list_numpy[:,0], color='blue')\n",
    "plt.bar(range(len(target_list_numpy)), target_list_numpy[:,0], color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "out_target=target_list_numpy[:,0]\n",
    "out_hyena_pearsonr=seq_list_numpy_hyena[:,0]\n",
    "out_nt_pearsonr=seq_list_numpy_nt[:,0]\n",
    "out_mamba_pearsonr=seq_list_numpy_mamba[:,0]\n",
    "out_bert2_pearsonr=seq_list_numpy_bert2[:,0]\n",
    "out_genalm_pearsonr=seq_list_numpy_genalm[:,0]\n",
    "def spearmanr_numpy(logits,y):\n",
    "    #compute spearmanr correlation for each class\n",
    "    output={}\n",
    "\n",
    "    metrices = []\n",
    "    spearmanrs = stats.spearmanr(logits, y)[0]\n",
    "    metrices.append(spearmanrs)\n",
    "    spearmanrs=np.nanmean(metrices,axis=0)\n",
    "    output['spearmanr']=spearmanrs\n",
    "    return spearmanrs\n",
    "\n",
    "max=np.max([np.max(out_target),np.max(out_hyena_pearsonr),np.max(out_mamba_pearsonr),np.max(out_nt_pearsonr),np.max(out_bert2_pearsonr),np.max(out_genalm_pearsonr)])\n",
    "min=np.min([np.min(out_target),np.min(out_hyena_pearsonr),np.min(out_mamba_pearsonr),np.min(out_nt_pearsonr),np.min(out_bert2_pearsonr),np.min(out_genalm_pearsonr)])\n",
    "\n",
    "courses=[]\n",
    "for i in range(target_list_numpy.shape[0]):\n",
    "    courses.append(i*0.1)\n",
    "fig,(ax1,ax2,ax3,ax4,ax5,ax6)=plt.subplots(6,1,figsize=(20,10),sharex=True)\n",
    "\n",
    "ax1.bar(courses, out_target, color ='blue',  align='edge',\n",
    "        width = 0.1)\n",
    "ax1.set_ylim(min,max)\n",
    "#remove x-axis label\n",
    "ax1.set_xticklabels([])\n",
    "#remove y-axis label\n",
    "ax1.set_yticklabels([])\n",
    "\n",
    "#remove x-axis ticks\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "#remove y-axis ticks\n",
    "ax1.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "#remove boundary\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax1.spines['left'].set_visible(False)\n",
    "\n",
    "# ax1_twin = ax1.twinx()\n",
    "# ax1_twin.set_xticklabels([])\n",
    "# ax1_twin.set_yticklabels([])\n",
    "# ax1_twin.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "# ax1_twin.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "# ax1_twin.spines['top'].set_visible(False)\n",
    "# ax1_twin.spines['right'].set_visible(False)\n",
    "# ax1_twin.spines['bottom'].set_visible(False)\n",
    "# ax1_twin.spines['left'].set_visible(False)\n",
    "\n",
    "ax2.bar(courses, out_hyena_pearsonr, color = 'blue', align='edge',\n",
    "        width = 0.1)\n",
    "ax2.set_ylim(min,max)\n",
    "ax2.set_xticklabels([])\n",
    "#remove y-axis label\n",
    "ax2.set_yticklabels([])\n",
    "\n",
    "#remove x-axis ticks\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "#remove y-axis ticks\n",
    "ax2.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "#remove boundary\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['bottom'].set_visible(False)\n",
    "ax2.spines['left'].set_visible(False)\n",
    "\n",
    "# ax2_twin = ax2.twinx()\n",
    "# ax2_twin.set_xticklabels([])\n",
    "# ax2_twin.set_yticklabels([])\n",
    "# ax2_twin.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "# ax2_twin.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "# ax2_twin.spines['top'].set_visible(False)\n",
    "# ax2_twin.spines['right'].set_visible(False)\n",
    "# ax2_twin.spines['bottom'].set_visible(False)\n",
    "# ax2_twin.spines['left'].set_visible(False)\n",
    "\n",
    "ax3.bar(courses, out_mamba_pearsonr, color = 'blue', align='edge',\n",
    "        width = 0.1)\n",
    "ax3.set_ylim(min,max)\n",
    "ax3.set_xticklabels([])\n",
    "#remove y-axis label\n",
    "ax3.set_yticklabels([])\n",
    "\n",
    "#remove x-axis ticks\n",
    "ax3.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "#remove y-axis ticks\n",
    "ax3.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "#remove boundary\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.spines['right'].set_visible(False)\n",
    "ax3.spines['bottom'].set_visible(False)\n",
    "ax3.spines['left'].set_visible(False)\n",
    "# ax3_twin = ax3.twinx()\n",
    "# ax3_twin.set_xticklabels([])\n",
    "# ax3_twin.set_yticklabels([])\n",
    "# ax3_twin.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "# ax3_twin.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "# ax3_twin.spines['top'].set_visible(False)\n",
    "# ax3_twin.spines['right'].set_visible(False)\n",
    "# ax3_twin.spines['bottom'].set_visible(False)\n",
    "# ax3_twin.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "ax4.bar(courses, out_bert2_pearsonr, color = 'blue', align='edge',\n",
    "        width = 0.1)\n",
    "ax4.set_ylim(min,max)\n",
    "ax4.set_xticklabels([])\n",
    "#remove y-axis label\n",
    "ax4.set_yticklabels([])\n",
    "\n",
    "\n",
    "#remove x-axis ticks\n",
    "ax4.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)        \n",
    "#remove y-axis ticks        \n",
    "ax4.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)        \n",
    "#remove boundary        \n",
    "ax4.spines['top'].set_visible(False)        \n",
    "ax4.spines['right'].set_visible(False)        \n",
    "ax4.spines['bottom'].set_visible(False)        \n",
    "ax4.spines['left'].set_visible(False)     \n",
    "\n",
    "# ax4_twin = ax4.twinx()\n",
    "# ax4_twin.set_ylim(min,max)\n",
    "# ax4_twin.set_xticklabels([])\n",
    "# ax4_twin.set_yticklabels([])\n",
    "# ax4_twin.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "# ax4_twin.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "# ax4_twin.spines['top'].set_visible(False)\n",
    "# ax4_twin.spines['right'].set_visible(False)\n",
    "# ax4_twin.spines['bottom'].set_visible(False)\n",
    "# ax4_twin.spines['left'].set_visible(False)\n",
    "\n",
    "ax5.bar(courses, out_genalm_pearsonr, color = 'blue', align='edge',\n",
    "        width = 0.1)\n",
    "ax5.set_ylim(min,max)\n",
    "ax5.set_xticklabels([])\n",
    "#remove y-axis label\n",
    "ax5.set_yticklabels([])\n",
    "\n",
    "\n",
    "#remove x-axis ticks\n",
    "ax5.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)        \n",
    "#remove y-axis ticks        \n",
    "ax5.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)        \n",
    "#remove boundary        \n",
    "ax5.spines['top'].set_visible(False)        \n",
    "ax5.spines['right'].set_visible(False)        \n",
    "ax5.spines['bottom'].set_visible(False)        \n",
    "ax5.spines['left'].set_visible(False)        \n",
    "\n",
    "\n",
    "# ax5_twin = ax5.twinx()\n",
    "# ax5_twin.set_xticklabels([])\n",
    "# ax5_twin.set_yticklabels([])    \n",
    "\n",
    "# ax5_twin.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "# ax5_twin.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "# ax5_twin.spines['top'].set_visible(False)\n",
    "# ax5_twin.spines['right'].set_visible(False)\n",
    "# ax5_twin.spines['bottom'].set_visible(False)\n",
    "# ax5_twin.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "ax6.bar(courses, out_nt_pearsonr, color = 'blue', align='edge',\n",
    "        width = 0.1)\n",
    "ax6.set_ylim(min,max)\n",
    "ax6.set_xticklabels([])\n",
    "#remove y-axis label\n",
    "ax6.set_yticklabels([])\n",
    "\n",
    "\n",
    "#remove x-axis ticks\n",
    "ax6.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)        \n",
    "#remove y-axis ticks        \n",
    "ax6.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)        \n",
    "#remove boundary        \n",
    "ax6.spines['top'].set_visible(False)        \n",
    "ax6.spines['right'].set_visible(False)        \n",
    "ax6.spines['bottom'].set_visible(False)        \n",
    "ax6.spines['left'].set_visible(False)   \n",
    "\n",
    "# ax6_twin = ax6.twinx()\n",
    "# # ax6_twin.set_xticklabels([])\n",
    "# # ax6_twin.set_yticklabels([])\n",
    "# ax6_twin.get_xaxis().set_ticks([])\n",
    "# ax6_twin.get_yaxis().set_ticks([])\n",
    "\n",
    "# # ax6_twin.tick_params(axis='x', which='both', bottom=False, top=False,left=False, right=False, labelbottom=False, labelleft=False)\n",
    "# # ax6_twin.tick_params(axis='y', which='both', left=False, right=False,bottom=False,top=False, labelleft=False)\n",
    "# ax6_twin.spines['top'].set_visible(False)\n",
    "# ax6_twin.spines['right'].set_visible(False)\n",
    "# ax6_twin.spines['bottom'].set_visible(False)\n",
    "# ax6_twin.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax1.yaxis.set_label_position('left')\n",
    "ax1.set_ylabel('GT', rotation=0, size=20,fontweight='bold', y=0.15,\n",
    "                   ha='left', va='center')\n",
    "\n",
    "ax2.yaxis.set_label_position('left')\n",
    "ax2.set_ylabel('HyenaDNA'+152*' '+'0.737', rotation=0, size=20,fontweight='bold',y=0.15,\n",
    "                   ha='left', va='center')\n",
    "ax2.yaxis.set_label_coords(-0.085,0.15)\n",
    "# ax2_twin.yaxis.set_label_position('right')\n",
    "# ax2_twin.set_ylabel(str(spearmanr_numpy(out_hyena_pearsonr,out_target).round(3)), rotation=0, size=20,fontweight='bold',y=0.1,\n",
    "                    \n",
    "#                    ha='center', va='center')\n",
    "ax3.yaxis.set_label_position('left')\n",
    "ax3.set_ylabel('Caduceus'+152*' '+'0.738', rotation=0, size=20,fontweight='bold',y=0.15,\n",
    "                   ha='left', va='center')\n",
    "ax3.yaxis.set_label_coords(-0.075,0.15)\n",
    "# ax3_twin.yaxis.set_label_position('right')\n",
    "# ax3_twin.set_ylabel(str(spearmanr_numpy(out_mamba_pearsonr,out_target).round(3)), rotation=0, size=20,fontweight='bold',y=0.1,\n",
    "                    \n",
    "#                    ha='center', va='center')\n",
    "#add y-axis label from both left and right side\n",
    "\n",
    "ax4.yaxis.set_label_position('left')\n",
    "ax4.set_ylabel('DNABERT2'+152*' '+'0.748', rotation=0, size=20,fontweight='bold',y=0.15,\n",
    "                   ha='left', va='center')\n",
    "ax4.yaxis.set_label_coords(-0.085,0.15)\n",
    "# ax4_twin.yaxis.set_label_position('right')\n",
    "# ax4_twin.set_ylabel(str(spearmanr_numpy(out_bert2_pearsonr,out_target).round(3)), rotation=0, size=20,fontweight='bold',y=0.1,\n",
    "                    \n",
    "#                    ha='center', va='center')\n",
    "\n",
    "ax5.yaxis.set_label_position('left')\n",
    "ax5.set_ylabel('GENA-LM'+152*' '+'0.723', rotation=0, size=20,fontweight='bold',y=0.2,\n",
    "                   ha='left', va='center')\n",
    "ax5.yaxis.set_label_coords(-0.07,0.15)\n",
    "# ax5_twin.yaxis.set_label_position('right')\n",
    "# ax5_twin.set_ylabel(str(spearmanr_numpy(out_genalm_pearsonr,out_target).round(3)), rotation=0, size=20,fontweight='bold',y=0.1,\n",
    "                    \n",
    "#                    ha='center', va='center')\n",
    "\n",
    "ax6.yaxis.set_label_position('left')\n",
    "ax6.set_ylabel('NT'+152*' '+'0.755', rotation=0, size=20,fontweight='bold',y=0.2,\n",
    "                   ha='left', va='center')\n",
    "# ax6.yaxis.set_label_coords(-0.0,0.1)\n",
    "# ax6_twin.yaxis.set_label_position('right')\n",
    "# ax6_twin.set_ylabel(str(spearmanr_numpy(out_nt_pearsonr,out_target).round(3)), rotation=0, size=20,fontweight='bold',y=0.1,\n",
    "                    \n",
    "#                    ha='center', va='center')\n",
    "\n",
    "\n",
    "plt.suptitle('Bulk RNA Expression',fontsize=25,y=0.95,fontweight='bold')\n",
    "fig.savefig(\"Bulk_RNA_Expression.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "#save as pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "out_target=target_list_numpy[:,0]\n",
    "out_hyena_pearsonr=seq_list_numpy_hyena[:,0]\n",
    "out_nt_pearsonr=seq_list_numpy_nt[:,0]\n",
    "out_mamba_pearsonr=seq_list_numpy_mamba[:,0]\n",
    "out_bert2_pearsonr=seq_list_numpy_bert2[:,0]\n",
    "out_genalm_pearsonr=seq_list_numpy_genalm[:,0]\n",
    "out_enformer_pearsonr=seq_list_numpy_enformer[:,0]\n",
    "def spearmanr_numpy(logits,y):\n",
    "    #compute spearmanr correlation for each class\n",
    "    output={}\n",
    "\n",
    "    metrices = []\n",
    "    spearmanrs = stats.spearmanr(logits, y)[0]\n",
    "    metrices.append(spearmanrs)\n",
    "    spearmanrs=np.nanmean(metrices,axis=0)\n",
    "    output['spearmanr']=spearmanrs\n",
    "    return spearmanrs\n",
    "\n",
    "max=np.max([np.max(out_target),np.max(out_hyena_pearsonr),np.max(out_mamba_pearsonr),np.max(out_nt_pearsonr),np.max(out_bert2_pearsonr),np.max(out_genalm_pearsonr)])\n",
    "min=np.min([np.min(out_target),np.min(out_hyena_pearsonr),np.min(out_mamba_pearsonr),np.min(out_nt_pearsonr),np.min(out_bert2_pearsonr),np.min(out_genalm_pearsonr)])\n",
    "\n",
    "courses=[]\n",
    "for i in range(target_list_numpy.shape[0]):\n",
    "    courses.append(i*0.1)\n",
    "fig,(ax1,ax2,ax3,ax4,ax5,ax6)=plt.subplots(6,1,figsize=(20,10),sharex=True)\n",
    "\n",
    "ax1.fill_between(courses, out_target, color ='blue')\n",
    "ax1.set_ylim(min,max)\n",
    "#remove x-axis label\n",
    "ax1.set_xticklabels([])\n",
    "#remove y-axis label\n",
    "ax1.set_yticklabels([])\n",
    "\n",
    "#remove x-axis ticks\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "#remove y-axis ticks\n",
    "ax1.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "#remove boundary\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax1.spines['left'].set_visible(False)\n",
    "\n",
    "# ax1_twin = ax1.twinx()\n",
    "# ax1_twin.set_xticklabels([])\n",
    "# ax1_twin.set_yticklabels([])\n",
    "# ax1_twin.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "# ax1_twin.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "# ax1_twin.spines['top'].set_visible(False)\n",
    "# ax1_twin.spines['right'].set_visible(False)\n",
    "# ax1_twin.spines['bottom'].set_visible(False)\n",
    "# ax1_twin.spines['left'].set_visible(False)\n",
    "\n",
    "ax2.fill_between(courses, out_hyena_pearsonr, color = 'blue')\n",
    "ax2.set_ylim(min,max)\n",
    "ax2.set_xticklabels([])\n",
    "#remove y-axis label\n",
    "ax2.set_yticklabels([])\n",
    "\n",
    "#remove x-axis ticks\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "#remove y-axis ticks\n",
    "ax2.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "#remove boundary\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['bottom'].set_visible(False)\n",
    "ax2.spines['left'].set_visible(False)\n",
    "\n",
    "# ax2_twin = ax2.twinx()\n",
    "# ax2_twin.set_xticklabels([])\n",
    "# ax2_twin.set_yticklabels([])\n",
    "# ax2_twin.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "# ax2_twin.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "# ax2_twin.spines['top'].set_visible(False)\n",
    "# ax2_twin.spines['right'].set_visible(False)\n",
    "# ax2_twin.spines['bottom'].set_visible(False)\n",
    "# ax2_twin.spines['left'].set_visible(False)\n",
    "\n",
    "ax3.fill_between(courses, out_mamba_pearsonr, color = 'blue')\n",
    "ax3.set_ylim(min,max)\n",
    "ax3.set_xticklabels([])\n",
    "#remove y-axis label\n",
    "ax3.set_yticklabels([])\n",
    "\n",
    "#remove x-axis ticks\n",
    "ax3.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "#remove y-axis ticks\n",
    "ax3.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "#remove boundary\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.spines['right'].set_visible(False)\n",
    "ax3.spines['bottom'].set_visible(False)\n",
    "ax3.spines['left'].set_visible(False)\n",
    "# ax3_twin = ax3.twinx()\n",
    "# ax3_twin.set_xticklabels([])\n",
    "# ax3_twin.set_yticklabels([])\n",
    "# ax3_twin.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "# ax3_twin.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "# ax3_twin.spines['top'].set_visible(False)\n",
    "# ax3_twin.spines['right'].set_visible(False)\n",
    "# ax3_twin.spines['bottom'].set_visible(False)\n",
    "# ax3_twin.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "ax4.fill_between(courses, out_bert2_pearsonr, color = 'blue')\n",
    "ax4.set_ylim(min,max)\n",
    "ax4.set_xticklabels([])\n",
    "#remove y-axis label\n",
    "ax4.set_yticklabels([])\n",
    "\n",
    "\n",
    "#remove x-axis ticks\n",
    "ax4.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)        \n",
    "#remove y-axis ticks        \n",
    "ax4.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)        \n",
    "#remove boundary        \n",
    "ax4.spines['top'].set_visible(False)        \n",
    "ax4.spines['right'].set_visible(False)        \n",
    "ax4.spines['bottom'].set_visible(False)        \n",
    "ax4.spines['left'].set_visible(False)     \n",
    "\n",
    "# ax4_twin = ax4.twinx()\n",
    "# ax4_twin.set_ylim(min,max)\n",
    "# ax4_twin.set_xticklabels([])\n",
    "# ax4_twin.set_yticklabels([])\n",
    "# ax4_twin.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "# ax4_twin.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "# ax4_twin.spines['top'].set_visible(False)\n",
    "# ax4_twin.spines['right'].set_visible(False)\n",
    "# ax4_twin.spines['bottom'].set_visible(False)\n",
    "# ax4_twin.spines['left'].set_visible(False)\n",
    "\n",
    "ax5.fill_between(courses, out_genalm_pearsonr, color = 'blue')\n",
    "ax5.set_ylim(min,max)\n",
    "ax5.set_xticklabels([])\n",
    "#remove y-axis label\n",
    "ax5.set_yticklabels([])\n",
    "\n",
    "\n",
    "#remove x-axis ticks\n",
    "ax5.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)        \n",
    "#remove y-axis ticks        \n",
    "ax5.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)        \n",
    "#remove boundary        \n",
    "ax5.spines['top'].set_visible(False)        \n",
    "ax5.spines['right'].set_visible(False)        \n",
    "ax5.spines['bottom'].set_visible(False)        \n",
    "ax5.spines['left'].set_visible(False)        \n",
    "\n",
    "\n",
    "# ax5_twin = ax5.twinx()\n",
    "# ax5_twin.set_xticklabels([])\n",
    "# ax5_twin.set_yticklabels([])    \n",
    "\n",
    "# ax5_twin.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "# ax5_twin.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "# ax5_twin.spines['top'].set_visible(False)\n",
    "# ax5_twin.spines['right'].set_visible(False)\n",
    "# ax5_twin.spines['bottom'].set_visible(False)\n",
    "# ax5_twin.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "ax6.fill_between(courses, out_nt_pearsonr, color = 'blue')\n",
    "ax6.set_ylim(min,max)\n",
    "ax6.set_xticklabels([])\n",
    "#remove y-axis label\n",
    "ax6.set_yticklabels([])\n",
    "\n",
    "\n",
    "#remove x-axis ticks\n",
    "ax6.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)        \n",
    "#remove y-axis ticks        \n",
    "ax6.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)        \n",
    "#remove boundary        \n",
    "ax6.spines['top'].set_visible(False)        \n",
    "ax6.spines['right'].set_visible(False)        \n",
    "ax6.spines['bottom'].set_visible(False)        \n",
    "ax6.spines['left'].set_visible(False)   \n",
    "\n",
    "# ax7.fill_between(courses, out_enformer_pearsonr, color = 'blue')\n",
    "# ax7.set_ylim(min,max)\n",
    "# ax7.set_xticklabels([])\n",
    "# #remove y-axis label\n",
    "# ax7.set_yticklabels([])\n",
    "\n",
    "\n",
    "#remove x-axis ticks\n",
    "# ax7.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)        \n",
    "# #remove y-axis ticks        \n",
    "# ax7.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)        \n",
    "# #remove boundary        \n",
    "# ax7.spines['top'].set_visible(False)        \n",
    "# ax7.spines['right'].set_visible(False)        \n",
    "# ax7.spines['bottom'].set_visible(False)        \n",
    "# ax7.spines['left'].set_visible(False)   \n",
    "\n",
    "\n",
    "# ax7_twin = ax7.twinx()\n",
    "# ax7_twin.set_xticklabels([])\n",
    "# ax6_twin = ax6.twinx()\n",
    "# # ax6_twin.set_xticklabels([])\n",
    "# # ax6_twin.set_yticklabels([])\n",
    "# ax6_twin.get_xaxis().set_ticks([])\n",
    "# ax6_twin.get_yaxis().set_ticks([])\n",
    "\n",
    "# # ax6_twin.tick_params(axis='x', which='both', bottom=False, top=False,left=False, right=False, labelbottom=False, labelleft=False)\n",
    "# # ax6_twin.tick_params(axis='y', which='both', left=False, right=False,bottom=False,top=False, labelleft=False)\n",
    "# ax6_twin.spines['top'].set_visible(False)\n",
    "# ax6_twin.spines['right'].set_visible(False)\n",
    "# ax6_twin.spines['bottom'].set_visible(False)\n",
    "# ax6_twin.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax1.yaxis.set_label_position('left')\n",
    "ax1.set_ylabel('GT', rotation=0, size=20,fontweight='bold', y=0.15,\n",
    "                   ha='left', va='center')\n",
    "\n",
    "ax2.yaxis.set_label_position('left')\n",
    "ax2.set_ylabel('HyenaDNA'+152*' '+'0.737', rotation=0, size=20,fontweight='bold',y=0.15,\n",
    "                   ha='left', va='center')\n",
    "ax2.yaxis.set_label_coords(-0.085,0.15)\n",
    "# ax2_twin.yaxis.set_label_position('right')\n",
    "# ax2_twin.set_ylabel(str(spearmanr_numpy(out_hyena_pearsonr,out_target).round(3)), rotation=0, size=20,fontweight='bold',y=0.1,\n",
    "                    \n",
    "#                    ha='center', va='center')\n",
    "ax3.yaxis.set_label_position('left')\n",
    "ax3.set_ylabel('Caduceus'+152*' '+'0.738', rotation=0, size=20,fontweight='bold',y=0.15,\n",
    "                   ha='left', va='center')\n",
    "ax3.yaxis.set_label_coords(-0.075,0.15)\n",
    "# ax3_twin.yaxis.set_label_position('right')\n",
    "# ax3_twin.set_ylabel(str(spearmanr_numpy(out_mamba_pearsonr,out_target).round(3)), rotation=0, size=20,fontweight='bold',y=0.1,\n",
    "                    \n",
    "#                    ha='center', va='center')\n",
    "#add y-axis label from both left and right side\n",
    "\n",
    "ax4.yaxis.set_label_position('left')\n",
    "ax4.set_ylabel('DNABERT2'+152*' '+'0.748', rotation=0, size=20,fontweight='bold',y=0.15,\n",
    "                   ha='left', va='center')\n",
    "ax4.yaxis.set_label_coords(-0.085,0.15)\n",
    "# ax4_twin.yaxis.set_label_position('right')\n",
    "# ax4_twin.set_ylabel(str(spearmanr_numpy(out_bert2_pearsonr,out_target).round(3)), rotation=0, size=20,fontweight='bold',y=0.1,\n",
    "                    \n",
    "#                    ha='center', va='center')\n",
    "\n",
    "ax5.yaxis.set_label_position('left')\n",
    "ax5.set_ylabel('GENA-LM'+152*' '+'0.723', rotation=0, size=20,fontweight='bold',y=0.2,\n",
    "                   ha='left', va='center')\n",
    "ax5.yaxis.set_label_coords(-0.07,0.15)\n",
    "# ax5_twin.yaxis.set_label_position('right')\n",
    "# ax5_twin.set_ylabel(str(spearmanr_numpy(out_genalm_pearsonr,out_target).round(3)), rotation=0, size=20,fontweight='bold',y=0.1,\n",
    "                    \n",
    "#                    ha='center', va='center')\n",
    "\n",
    "ax6.yaxis.set_label_position('left')\n",
    "ax6.set_ylabel('NT'+152*' '+'0.755', rotation=0, size=20,fontweight='bold',y=0.2,\n",
    "                   ha='left', va='center')\n",
    "# ax6.yaxis.set_label_coords(-0.0,0.1)\n",
    "# ax6_twin.yaxis.set_label_position('right')\n",
    "# ax6_twin.set_ylabel(str(spearmanr_numpy(out_nt_pearsonr,out_target).round(3)), rotation=0, size=20,fontweight='bold',y=0.1,\n",
    "                    \n",
    "#                    ha='center', va='center')\n",
    "\n",
    "# ax7.yaxis.set_label_position('left')\n",
    "# ax7.set_ylabel('Enformer'+152*' '+'0.744', rotation=0, size=20,fontweight='bold',y=0.2,\n",
    "#                    ha='left', va='center')\n",
    "plt.suptitle('Bulk RNA Expression',fontsize=25,y=0.95,fontweight='bold')\n",
    "fig.savefig(\"Bulk_RNA_Expression.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "fig.savefig(\"Bulk_RNA_Expression.png\", format=\"png\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "#save as pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
