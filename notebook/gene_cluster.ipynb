{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pyfaidx import Fasta\n",
    "import torch\n",
    "import shutil\n",
    "import gzip\n",
    "import random\n",
    "from typing import Optional, Union, Dict, List\n",
    "#set seed for random\n",
    "random.seed(42)\n",
    "import collections\n",
    "SPECIES_CHROMOSOME_SPLITS = {\n",
    "    'human' : {\n",
    "        'train' : [ '2', '4', '6', '8','14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', ],\n",
    "        'valid' : ['1', '3', '12', '13',],\n",
    "        'test' : [ '5', '7', '9', '10', '11',],\n",
    "    },\n",
    "    'lemur' : {\n",
    "        'train' : [ '2', '4', '6', '8','14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', 'X', 'Y', ],\n",
    "        'valid' : ['1', '3', '12', '13',],\n",
    "        'test' : [ '5', '7', '9', '10', '11',],\n",
    "    },\n",
    "    'goat' : {\n",
    "        'train' : [ '2', '4', '6', '8','14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', 'X', 'Y', ],\n",
    "        'valid' : ['1', '3', '12', '13',],\n",
    "        'test' : [ '5', '7', '9', '10', '11',],\n",
    "    },\n",
    "    'sheep' : {\n",
    "        'train' : [ '2', '4', '6', '8','14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', 'X', 'Y', ],\n",
    "        'valid' : ['1', '3', '12', '13',],\n",
    "        'test' : [ '5', '7', '9', '10', '11',],\n",
    "    },\n",
    "    'pig' : {\n",
    "        'train' : [ '2', '4', '6', '8','14', '15', '16', '17', '18', 'X', 'Y', ],\n",
    "        'valid' : ['1', '3', '12', '13',],\n",
    "        'test' : [ '5', '7', '9', '10', '11',],\n",
    "    },\n",
    "    'mouse' : {\n",
    "        'train' : [ '2', '4', '6', '8', '14', '15', '16', '17', '18', '19', 'X', ],\n",
    "        'valid' : ['1', '3', '12', '13',],\n",
    "        'test' : [ '5', '7', '9', '10', '11',],\n",
    "    },\n",
    "    'gorilla' : {\n",
    "        'train' : [ '2A', '2B', '4', '6', '8', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', ],\n",
    "        'valid' : ['1', '3', '12', '13',],\n",
    "        'test' : [ '5', '7', '9', '10', '11',],\n",
    "    },\n",
    "    'orangutan' : {\n",
    "        'train' : [ '2A', '2B', '4', '6', '8', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', ],\n",
    "        'valid' : ['1', '3', '12', '13',],\n",
    "        'test' : [ '5', '7', '9', '10', '11',],\n",
    "    },\n",
    "    'chimpanzee' : {\n",
    "        'train' : [ '2A', '2B', '4', '6', '8', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', ],\n",
    "        'valid' : ['1', '3', '12', '13',],\n",
    "        'test' : [ '5', '7', '9', '10', '11',],\n",
    "    },\n",
    "    'hippo' : {\n",
    "        'train' : [ '2', '4', '6', '8', '14', '15', '16', '17', 'X', ],\n",
    "        'valid' : ['1', '3', '12', '13',],\n",
    "        'test' : [ '5', '7', '9', '10', '11',],\n",
    "    }\n",
    "}\n",
    "\n",
    "fastas: Dict[str, Dict[str, Fasta]] = collections.defaultdict(dict) # [key] = species -> dict where [key] = chromosome, [value] = Fasta object\n",
    "chromosomes: Dict[str, List[str]] = {} # [key] = species, [value] = list of chromosomes in this split\n",
    "chromosome_weights: Dict[str, List[float]] = {} # [key] = species, [value] = list where [idx] = self.chromosomes[species][idx], [value] = weight\n",
    "species_weights: List[float] = []\n",
    "species=['human','mouse','hippo','pig','lemur']\n",
    "species_dir='data/species'\n",
    "max_length=3000\n",
    "split='valid'\n",
    "chromosome_weights='uniform'\n",
    "species_weights='uniform'\n",
    "for spec in species:\n",
    "            species_path = Path(species_dir) / spec\n",
    "            assert species_path.exists(), f'The path `{species_path}` does not exist for species `{spec}`. Please point to a valid directory containing your species fna.gz files.'\n",
    "\n",
    "            # Select chromosomes for this split\n",
    "            assert spec in SPECIES_CHROMOSOME_SPLITS, f'Unrecognized species `{spec}`. Valid species are: {list(SPECIES_CHROMOSOME_SPLITS.keys())}.'\n",
    "            chromosomes[spec] = SPECIES_CHROMOSOME_SPLITS[spec][split]\n",
    "\n",
    "            # Load all .fna files of chromosomes in this split\n",
    "            for chromosome in chromosomes[spec]:\n",
    "                # Unzip if necessary\n",
    "                gz_file_path = os.path.join(species_path, f'chr{chromosome}.fna.gz')\n",
    "                if os.path.exists(gz_file_path) and not (\n",
    "                    os.path.exists(os.path.join(species_path, f'chr{chromosome}.fna')) or\n",
    "                    os.path.exists(os.path.join(species_path, f'chr{chromosome}.fa'))\n",
    "                ):\n",
    "                    \n",
    "                    print(f\"Unzipping {gz_file_path}...\")\n",
    "                    with gzip.open(gz_file_path, 'rb') as f_in:\n",
    "                        with open(os.path.join(species_path, f'chr{chromosome}.fna'), 'wb') as f_out:\n",
    "                            shutil.copyfileobj(f_in, f_out)\n",
    "                # Read .fna or .fa file, whichever we can find\n",
    "                file_paths = [ os.path.join(species_path, x) for x in [ f'chr{chromosome}.fna', f'chr{chromosome}.fa' ] ]\n",
    "                is_file_found: bool = False\n",
    "                for file_path in file_paths:\n",
    "                    if os.path.exists(file_path):\n",
    "                        if chromosome not in fastas[spec]:\n",
    "                            fastas[spec][chromosome] = Fasta(file_path, sequence_always_upper=True)\n",
    "                        is_file_found = True\n",
    "                if not is_file_found:\n",
    "                    raise FileNotFoundError(f'Could not find any of these files: `{file_paths}`. Please point to a valid directory containing all .fna files for species `{spec}`.\\nExpected chromosomes: {self.chromosomes[spec]}.')\n",
    "\n",
    "            \n",
    "            print(f\"Species: {spec}\")\n",
    "            print(f\"Split: {split}\")\n",
    "            print(f\"Chromosomes: {chromosomes[spec]}\")\n",
    "            print(f\"Loaded {len(fastas[spec])} FASTA files from {species_path}: {list(fastas[spec].keys())}\")\n",
    "\n",
    "if isinstance(chromosome_weights, dict):\n",
    "    assert len(chromosome_weights) == len(species), f\"`chromosome_weights` must have a weight for each species. Expected {len(species)} weights, instead got {len(chromosome_weights)}.\"\n",
    "    chromosome_weights = chromosome_weights\n",
    "elif chromosome_weights == 'uniform':\n",
    "    chromosome_weights = {\n",
    "        spec: 'uniform'\n",
    "        for spec in species\n",
    "    }\n",
    "elif chromosome_weights == 'weighted_by_bp':\n",
    "    chromosome_weights = {\n",
    "        spec: 'weighted_by_bp'\n",
    "        for spec in species\n",
    "    }\n",
    "else:\n",
    "    raise ValueError(f\"Invalid chromosome_weights: {chromosome_weights}. Must be 'uniform', 'weighted_by_bp', or a dict of species -> chromosome weights.\")\n",
    "\n",
    "for spec, strategy_or_weights in chromosome_weights.items():\n",
    "    if isinstance(strategy_or_weights, str):\n",
    "        if strategy_or_weights == 'uniform':\n",
    "            # Uniform weights\n",
    "            chromosome_weights[spec] = [1] * len(chromosomes[spec])\n",
    "        elif strategy_or_weights == 'weighted_by_bp':\n",
    "            # Weight by number of base pairs in each chromosome\n",
    "            chromosome_weights[spec] = [\n",
    "                len(fastas[spec][chromosome])\n",
    "                for chromosome in chromosomes[spec]\n",
    "            ]\n",
    "            chromosome_weights[spec] = [w / sum(chromosome_weights[spec]) for w in chromosome_weights[spec]]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid chromosome_weights strategy: {strategy_or_weights}. Must be 'uniform' or 'weighted_by_bp'.\")\n",
    "    elif isinstance(strategy_or_weights, list):\n",
    "        # Check that all chromosomes are accounted for\n",
    "        assert set(strategy_or_weights.keys()) == set(chromosomes[spec]), f\"`chromosome_weights` must have a weight for each chromosome. Expected {chromosomes[spec]}, instead got {strategy_or_weights.keys()}.\"\n",
    "        chromosome_weights[spec] = strategy_or_weights\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid chromosome_weights: {chromosome_weights}. Must be 'uniform', 'weighted_by_bp', or a dict of species -> chromosome weights.\")\n",
    "    \n",
    "# Set species weights for sampling\n",
    "if isinstance(species_weights, list):\n",
    "    assert len(species_weights) == len(species), f\"`species_weights` must have a weight for each species. Expected {len(species)} weights, instead got {len(species_weights)}.\"\n",
    "    species_weights = species_weights\n",
    "elif species_weights == 'uniform':\n",
    "    # Uniform weights\n",
    "    species_weights = [1] * len(species)\n",
    "elif species_weights == 'weighted_by_bp':\n",
    "    # Weight by number of base pairs in each chromosome\n",
    "    species_weights = [\n",
    "        sum([ \n",
    "            len(fasta) \n",
    "            for fasta in fastas[spec].values() \n",
    "        ])\n",
    "        for spec in species\n",
    "    ]\n",
    "    species_weights = [w / sum(species_weights) for w in species_weights]\n",
    "else:\n",
    "    raise ValueError(f\"Invalid species_weights: {species_weights}. Must be 'uniform', 'weighted_by_bp', or a dict of species -> chromosome weights.\")\n",
    "    \n",
    "\n",
    "print(f\"Species weights: {list(zip(species, species_weights))}\")\n",
    "print(f\"Chromosome weights: {chromosome_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_kmer(seq: str, kmer: int) -> str:\n",
    "        return \" \".join(seq[i : i + kmer] for i in range(0, len(seq), kmer)).upper()\n",
    "\n",
    "def sample_sequence(species, chromosomes, species_weights, chromosome_weights, fastas, max_length,tokenizer,tokenizer_name):\n",
    "    spec: str = random.choices(species, weights=species_weights, k=1)[0]\n",
    "    chromosome = random.choices(chromosomes[spec], weights=chromosome_weights[spec], k=1)[0]\n",
    "    fasta = fastas[spec][chromosome][0] # idx into 0 b/c only one fasta per chromosome\n",
    "    chromosome_length: int = len(fasta)\n",
    "    left = 0\n",
    "    right = chromosome_length - max_length\n",
    "    start: int = random.randint(left, right)\n",
    "    end: int = start + max_length\n",
    "    seq = str(fasta[start:min(end, right)])\n",
    "\n",
    "    # pad with Ns if necessary\n",
    "    seq = seq.rjust(end - start, \"N\")\n",
    "    seq = seq[:max_length]\n",
    "\n",
    "    \n",
    "    assert len(seq) == max_length, f'Length of sequence ({len(seq)}) from interval ({start}, {end}) of chromosome {chromosome} (len={chromosome_length}) is not equal to `self.max_length` ({self.max_length})'\n",
    "\n",
    "\n",
    "    # print(f\"Sampled species: {spec}\")\n",
    "    # print(f\"Sampled chromosome: {chromosome}\")\n",
    "    # print(f\"Sampled sequence ({start}, {end}) of len={len(seq)}: {seq[:10]}...{seq[-10:]}\")\n",
    "    \n",
    "    assert tokenizer is not None, f\"Tokenizer cannot be `None`.\"\n",
    "    if(tokenizer_name == 'genslm' or tokenizer_name == 'bert'):\n",
    "            seq = group_by_kmer(seq, 3)\n",
    "    elif tokenizer_name == 'char':\n",
    "        seq = tokenizer(seq, add_special_tokens=False)  # add cls and eos token (+2)\n",
    "        seq = seq[\"input_ids\"]  # get input_ids\n",
    "        # need to handle eos here\n",
    "        \n",
    "    elif tokenizer_name == 'bpe':\n",
    "        seq = tokenizer(seq, \n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "            truncation=True,\n",
    "        )  # add cls and eos token (+2)\n",
    "        # get input_id\n",
    "    else:\n",
    "        # raise ValueError(f\"Invalid tokenizer name: {self.tokenizer_name}\")\n",
    "        seq = tokenizer(seq,\n",
    "            add_special_tokens= False,  # this is what controls adding eos\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "        seq = seq[\"input_ids\"]\n",
    "\n",
    "    # convert to tensor\n",
    "    seq = torch.LongTensor(seq)  # hack, remove the initial cls tokens for now\n",
    "\n",
    "    data = seq[:-1].clone()  # remove eos\n",
    "    target = species.index(spec)\n",
    "\n",
    "    \n",
    "        \n",
    "    return data, target\n",
    "\n",
    "restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[..., -1:, :]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model from automodel\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel,AutoTokenizer\n",
    "state_dict='weight/hyenadna/hyenadna-large-1m-seqlen'\n",
    "tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "hyenaDNA=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "hyenaDNA_decoder=torch.nn.Linear(256,5).to('cuda')\n",
    "checkpoint=torch.load('outputs/2024-04-07/01-43-51-388066/checkpoints/val/accuracy.ckpt')['state_dict']\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "        checkpoint, \"model.backbone.\"\n",
    "    )\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "        checkpoint, \"decoder.0.output_transform.\"\n",
    "    )\n",
    "#print model.keys()\n",
    "hyenaDNA.load_state_dict(checkpoint,strict=False)\n",
    "hyenaDNA_decoder.load_state_dict(checkpoint,strict=False)\n",
    "hyenaDNA.eval()\n",
    "hyenaDNA_decoder.eval()\n",
    "all_embeddings_hyena=[]\n",
    "species_labels_hyena=[]\n",
    "batch_size=1000\n",
    "#load data\n",
    "equal=0\n",
    "for i in range (batch_size):\n",
    "    data,target=sample_sequence(species,chromosomes,species_weights,chromosome_weights,fastas,max_length,tokenizer,'char')\n",
    "    data=data.unsqueeze(0).to('cuda')\n",
    "    # print(data.shape)\n",
    "    # print(target)\n",
    "\n",
    "\n",
    "    logits=hyenaDNA(data).last_hidden_state\n",
    "    \n",
    "    \n",
    "    logits=restrict(logits)\n",
    "    all_embeddings_hyena.append(logits.squeeze(0).squeeze(0).detach().cpu())\n",
    "    species_labels_hyena.append(target)\n",
    "    #print shape of logits\n",
    "    output=hyenaDNA_decoder(logits)\n",
    "    output=output.squeeze(0)\n",
    "    #output argmax\n",
    "    predicted_label=torch.argmax(output,dim=1)\n",
    "    equal+=int(predicted_label==target)\n",
    "#calculate accuracy\n",
    "accuracy=equal/batch_size\n",
    "accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "# from umap import UMAP\n",
    "print(all_embeddings_hyena[0].shape)\n",
    "tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30)\n",
    "all_embeddings_2d_hyena = tsne.fit_transform(np.array(all_embeddings_hyena))\n",
    "plt.clf()\n",
    "needed_folders_names = ['human','mouse', 'hippo','pig', 'lemur']\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "#remove axis and boundaries\n",
    "plt.axis('off')\n",
    "plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "s = plt.scatter(*all_embeddings_2d_hyena.T, c=species_labels_hyena, s=20, alpha=.5, cmap=mpl.colormaps['jet'])\n",
    "plt.legend(s.legend_elements()[0], list(map(lambda n: n.split('_')[-1], needed_folders_names)), fontsize=14)\n",
    "plt.title('HyenaDNA', fontsize=30)\n",
    "plt.savefig('HyenaDNA.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel,AutoTokenizer\n",
    "state_dict='weight/dnabert2'\n",
    "tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "dnabert2=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "DNABERT2_decoder=torch.nn.Linear(768,5).to('cuda')\n",
    "checkpoint=torch.load('outputs/2024-04-07/02-10-10-895046/checkpoints/val/accuracy.ckpt')['state_dict']\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "        checkpoint, \"model.backbone.\"\n",
    "    )\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "        checkpoint, \"decoder.0.output_transform.\"\n",
    "    )\n",
    "#print model.keys()\n",
    "dnabert2.load_state_dict(checkpoint,strict=False)\n",
    "DNABERT2_decoder.load_state_dict(checkpoint,strict=False)\n",
    "dnabert2.eval()\n",
    "DNABERT2_decoder.eval()\n",
    "all_embeddings_dnabert2=[]\n",
    "species_labels_dnabert2=[]\n",
    "batch_size=1000\n",
    "#load data\n",
    "equal=0\n",
    "for i in range (batch_size):\n",
    "    #no gradient\n",
    "    with torch.no_grad():\n",
    "        data,target=sample_sequence(species,chromosomes,species_weights,chromosome_weights,fastas,max_length,tokenizer,'dnabert2')\n",
    "        data=data.unsqueeze(0).to('cuda')\n",
    "        # print(data.shape)\n",
    "        # print(target)\n",
    "\n",
    "\n",
    "        logits=dnabert2(input_ids=data,output_hidden_states=True,)[0]\n",
    "        \n",
    "        \n",
    "        logits=restrict(logits)\n",
    "        all_embeddings_dnabert2.append(logits.squeeze(0).squeeze(0).detach().cpu())\n",
    "        species_labels_dnabert2.append(target)\n",
    "        #print shape of logits\n",
    "        output=DNABERT2_decoder(logits)\n",
    "        output=output.squeeze(0)\n",
    "        #output argmax\n",
    "        predicted_label=torch.argmax(output,dim=1)\n",
    "        equal+=int(predicted_label==target)\n",
    "        print(i)\n",
    "#calculate accuracy\n",
    "accuracy=equal/batch_size\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "# from umap import UMAP\n",
    "print(all_embeddings_dnabert2[0].shape)\n",
    "tsne2 = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30)\n",
    "all_embeddings_2d_DNABERT = tsne2.fit_transform(np.array(all_embeddings_dnabert2))\n",
    "plt.clf()\n",
    "needed_folders_names = ['human','mouse', 'hippo','pig', 'lemur']\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "s = plt.scatter(*all_embeddings_2d_DNABERT.T, c=species_labels_dnabert2, s=12, alpha=.5, cmap=mpl.colormaps['jet'])\n",
    "plt.legend(s.legend_elements()[0], list(map(lambda n: n.split('_')[-1], needed_folders_names)), fontsize=14)\n",
    "\n",
    "plt.title('DNABERT-2')\n",
    "plt.savefig('DNABERT-2.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot two figures side by side\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt, (fig1,fig2)= plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# plot the first figure\n",
    "fig1.scatter(*all_embeddings_2d_DNABERT.T, c=species_labels_dnabert2, s=20, alpha=.5, cmap=mpl.colormaps['jet'])\n",
    "fig2.scatter(*all_embeddings_2d_hyena.T, c=species_labels_hyena, s=20, alpha=.5, cmap=mpl.colormaps['jet'])\n",
    "#remove axis and boundary for both figure\n",
    "fig1.axis('off')\n",
    "fig2.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel,AutoTokenizer\n",
    "state_dict='weight/genalm/gena-lm-bigbird-base-t2t'\n",
    "tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "genalm=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "genalm_decoder=torch.nn.Linear(768,5).to('cuda')\n",
    "checkpoint=torch.load('/outputs/2024-04-07/04-46-00-609768/checkpoints/val/accuracy.ckpt')['state_dict']\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "        checkpoint, \"model.backbone.\"\n",
    "    )\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "        checkpoint, \"decoder.0.output_transform.\"\n",
    "    )\n",
    "#print model.keys()\n",
    "genalm.load_state_dict(checkpoint,strict=False)\n",
    "genalm_decoder.load_state_dict(checkpoint,strict=False)\n",
    "genalm.eval()\n",
    "genalm_decoder.eval()\n",
    "all_embeddings_genalm=[]\n",
    "species_labels_genalm=[]\n",
    "batch_size=1000\n",
    "#load data\n",
    "equal=0\n",
    "for i in range (batch_size):\n",
    "    #no gradient\n",
    "    with torch.no_grad():\n",
    "        data,target=sample_sequence(species,chromosomes,species_weights,chromosome_weights,fastas,max_length,tokenizer,'genalm')\n",
    "        data=data.unsqueeze(0).to('cuda')\n",
    "        # print(data.shape)\n",
    "        # print(target)\n",
    "\n",
    "\n",
    "        logits=genalm(input_ids=data, output_hidden_states=True,).hidden_states[-1]\n",
    "        \n",
    "        \n",
    "        logits=restrict(logits)\n",
    "        all_embeddings_genalm.append(logits.squeeze(0).squeeze(0).detach().cpu())\n",
    "        species_labels_genalm.append(target)\n",
    "        #print shape of logits\n",
    "        output=genalm_decoder(logits)\n",
    "        output=output.squeeze(0)\n",
    "        #output argmax\n",
    "        predicted_label=torch.argmax(output,dim=1)\n",
    "        equal+=int(predicted_label==target)\n",
    "        print(i)\n",
    "#calculate accuracy\n",
    "accuracy=equal/batch_size\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "# from umap import UMAP\n",
    "print(all_embeddings_genalm[0].shape)\n",
    "tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30)\n",
    "all_embeddings_2d_gena = tsne.fit_transform(np.array(all_embeddings_genalm))\n",
    "plt.clf()\n",
    "needed_folders_names = ['human','mouse', 'hippo','pig', 'lemur']\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "s = plt.scatter(*all_embeddings_2d_gena.T, c=species_labels_genalm, s=12, alpha=.5, cmap=mpl.colormaps['jet'])\n",
    "plt.legend(s.legend_elements()[0], list(map(lambda n: n.split('_')[-1], needed_folders_names)), fontsize=14)\n",
    "plt.title('GENA-LM')\n",
    "plt.savefig('GENA-LM.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel,AutoTokenizer,AutoModelForMaskedLM\n",
    "state_dict='/weight/nt/nucleotide-transformer-v2-500m-multi-species'\n",
    "tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "NT=AutoModelForMaskedLM.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "NT_decoder=torch.nn.Linear(1024,5).to('cuda')\n",
    "checkpoint=torch.load('/outputs/2024-04-07/06-43-55-513734/checkpoints/val/accuracy.ckpt')['state_dict']\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "        checkpoint, \"model.backbone.\"\n",
    "    )\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "        checkpoint, \"decoder.0.output_transform.\"\n",
    "    )\n",
    "#print model.keys()\n",
    "NT.load_state_dict(checkpoint,strict=False)\n",
    "NT_decoder.load_state_dict(checkpoint,strict=False)\n",
    "NT.eval()\n",
    "NT_decoder.eval()\n",
    "all_embeddings_NT=[]\n",
    "species_labels_NT=[]\n",
    "batch_size=1000\n",
    "#load data\n",
    "equal=0\n",
    "for i in range (batch_size):\n",
    "    #no gradient\n",
    "    with torch.no_grad():\n",
    "        data,target=sample_sequence(species,chromosomes,species_weights,chromosome_weights,fastas,max_length,tokenizer,'NT')\n",
    "        data=data.unsqueeze(0).to('cuda')\n",
    "        # print(data.shape)\n",
    "        # print(target)\n",
    "\n",
    "\n",
    "        logits=NT(data,output_hidden_states=True)['hidden_states'][-1] \n",
    "        \n",
    "        \n",
    "        logits=restrict(logits)\n",
    "        all_embeddings_NT.append(logits.squeeze(0).squeeze(0).detach().cpu())\n",
    "        species_labels_NT.append(target)\n",
    "        #print shape of logits\n",
    "        output=NT_decoder(logits)\n",
    "        output=output.squeeze(0)\n",
    "        #output argmax\n",
    "        predicted_label=torch.argmax(output,dim=1)\n",
    "        equal+=int(predicted_label==target)\n",
    "        print(i)\n",
    "#calculate accuracy\n",
    "accuracy=equal/batch_size\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "# from umap import UMAP\n",
    "print(all_embeddings_NT[0].shape)\n",
    "tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30)\n",
    "all_embeddings_2d_NT = tsne.fit_transform(np.array(all_embeddings_NT))\n",
    "plt.clf()\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "needed_folders_names = ['human','mouse', 'hippo','pig', 'lemur']\n",
    "s = plt.scatter(*all_embeddings_2d_NT.T, c=species_labels_NT, s=12, alpha=.5, cmap=mpl.colormaps['jet'])\n",
    "plt.legend(s.legend_elements()[0], list(map(lambda n: n.split('_')[-1], needed_folders_names)), fontsize=14)\n",
    "plt.title('Nucleotide Transformer')\n",
    "plt.savefig('Nucleotide Transformer.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel,AutoTokenizer,AutoModelForMaskedLM\n",
    "state_dict='/weight/mamba'\n",
    "tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "mamba=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "mamba_decoder=torch.nn.Linear(256,5).to('cuda')\n",
    "checkpoint=torch.load('/outputs/2024-04-26/14-25-29-745801/checkpoints/val/accuracy.ckpt')['state_dict']\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "        checkpoint, \"model.backbone.\"\n",
    "    )\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "        checkpoint, \"decoder.0.output_transform.\"\n",
    "    )\n",
    "#print model.keys()\n",
    "mamba.load_state_dict(checkpoint,strict=False)\n",
    "mamba_decoder.load_state_dict(checkpoint,strict=False)\n",
    "mamba.eval()\n",
    "mamba_decoder.eval()\n",
    "all_embeddings_mamba=[]\n",
    "species_labels_mamba=[]\n",
    "batch_size=1000\n",
    "#load data\n",
    "equal=0\n",
    "for i in range (batch_size):\n",
    "    #no gradient\n",
    "    with torch.no_grad():\n",
    "        data,target=sample_sequence(species,chromosomes,species_weights,chromosome_weights,fastas,max_length,tokenizer,'NT')\n",
    "        data=data.unsqueeze(0).to('cuda')\n",
    "        # print(data.shape)\n",
    "        # print(target)\n",
    "\n",
    "\n",
    "        logits=mamba(data,output_hidden_states=True).last_hidden_state\n",
    "        \n",
    "        \n",
    "        logits=restrict(logits)\n",
    "        all_embeddings_mamba.append(logits.squeeze(0).squeeze(0).detach().cpu())\n",
    "        species_labels_mamba.append(target)\n",
    "        #print shape of logits\n",
    "        output=mamba_decoder(logits)\n",
    "        output=output.squeeze(0)\n",
    "        #output argmax\n",
    "        predicted_label=torch.argmax(output,dim=1)\n",
    "        equal+=int(predicted_label==target)\n",
    "        print(i)\n",
    "#calculate accuracy\n",
    "accuracy=equal/batch_size\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "# from umap import UMAP\n",
    "print(all_embeddings_mamba[0].shape)\n",
    "tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30)\n",
    "all_embeddings_2d_mamba = tsne.fit_transform(np.array(all_embeddings_mamba))\n",
    "plt.clf()\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "needed_folders_names = ['human','mouse', 'hippo','pig', 'lemur']\n",
    "s = plt.scatter(*all_embeddings_2d_mamba.T, c=species_labels_mamba, s=12, alpha=.5, cmap=mpl.colormaps['jet'])\n",
    "plt.legend(s.legend_elements()[0], list(map(lambda n: n.split('_')[-1], needed_folders_names)), fontsize=14)\n",
    "plt.title('Nucleotide Transformer')\n",
    "plt.savefig('Nucleotide Transformer.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt, (fig1,fig2,fig3,fig4,fig5)= plt.subplots(1, 5, figsize=(20, 5))\n",
    "species=['human','mouse','hippo','pig','lemur']\n",
    "color_map={0:'blue',1:'red',2:'green',3:'yellow',4:'purple'}\n",
    "\n",
    "#map list of int to list of string\n",
    "species_labels_dnabert2_color = [color_map[i] for i in species_labels_dnabert2]\n",
    "species_labels_hyena_color = [color_map[i] for i in species_labels_hyena]\n",
    "species_labels_genalm_color = [color_map[i] for i in species_labels_genalm]\n",
    "species_labels_NT_color = [color_map[i] for i in species_labels_NT]\n",
    "species_labels_mamba_color = [color_map[i] for i in species_labels_mamba]\n",
    "\n",
    "# plot the first figure\n",
    "type1=fig1.scatter(*all_embeddings_2d_DNABERT.T, c=species_labels_dnabert2_color, s=20, alpha=.5, cmap=mpl.colormaps['jet'])\n",
    "fig2.scatter(*all_embeddings_2d_hyena.T, c=species_labels_hyena_color, s=20, alpha=.5, cmap=mpl.colormaps['jet'])\n",
    "fig3.scatter(*all_embeddings_2d_gena.T, c=species_labels_genalm_color, s=20, alpha=.5, cmap=mpl.colormaps['jet'])\n",
    "fig4.scatter(*all_embeddings_2d_NT.T, c=species_labels_NT_color, s=20, alpha=.5, cmap=mpl.colormaps['jet'])\n",
    "fig5.scatter(*all_embeddings_2d_mamba.T, c=species_labels_mamba_color, s=20, alpha=.5, cmap=mpl.colormaps['jet'])\n",
    "\n",
    "fig1.set_title('DNABERT')\n",
    "fig2.set_title('Hyena')\n",
    "fig3.set_title('GENA-LM')\n",
    "fig4.set_title('NT')\n",
    "fig5.set_title('Mamba')\n",
    "#remove axis and boundary for both figure\n",
    "fig1.axis('off')\n",
    "fig2.axis('off')\n",
    "fig3.axis('off')\n",
    "fig4.axis('off')\n",
    "fig5.axis('off')\n",
    "#show the label of speciesax\n",
    "\n",
    "#add color note for the first figure\n",
    "species_color_map = {'human': '0','mouse': '1', 'hippo': '2', 'pig': '3', 'lemur': '4'}\n",
    "\n",
    "\n",
    "species=['human','mouse','hippo','pig','lemur']\n",
    "#map species to color\n",
    "\n",
    "\n",
    "#add colorbar for the first figure\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(species,ncol=5,\n",
    "                    loc=\"lower center\", title=\"type\",\n",
    "                    bbox_to_anchor=(0.5, -0.1),\n",
    "                    fancybox=True, shadow=True,\n",
    "                    fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "figure,(axes1, axes2, axes3, axes4, axes5)=plt.subplots(1, 5,figsize=(20,5))\n",
    "axes1.axis('off')\n",
    "axes2.axis('off')\n",
    "axes3.axis('off')\n",
    "axes4.axis('off')\n",
    "axes5.axis('off')\n",
    "\n",
    "axes1.set_title('DNABERT',fontsize=20)\n",
    "axes2.set_title('Hyena',fontsize=20)\n",
    "axes3.set_title('GENA-LM',fontsize=20)\n",
    "axes4.set_title('NT',fontsize=20)\n",
    "axes5.set_title('Caduceus',fontsize=20)\n",
    "\n",
    "type0_x = []\n",
    "type0_y = []\n",
    "type1_x = []\n",
    "type1_y = []\n",
    "type2_x = []\n",
    "type2_y = []\n",
    "type3_x = []\n",
    "type3_y = []\n",
    "type4_x = []\n",
    "type4_y = []\n",
    "\n",
    "species=['human','mouse','hippo','pig','lemur']\n",
    "print(all_embeddings_2d_DNABERT.T.shape)\n",
    "for i in range(len(species_labels_dnabert2)):\n",
    "    if species_labels_dnabert2[i] == 0:\n",
    "        type0_x.append(all_embeddings_2d_DNABERT[i][0])\n",
    "        type0_y.append(all_embeddings_2d_DNABERT[i][1])\n",
    "    elif species_labels_dnabert2[i] == 1:\n",
    "        type1_x.append(all_embeddings_2d_DNABERT[i][0])\n",
    "        type1_y.append(all_embeddings_2d_DNABERT[i][1])\n",
    "    elif species_labels_dnabert2[i] == 2:\n",
    "        type2_x.append(all_embeddings_2d_DNABERT[i][0])\n",
    "        type2_y.append(all_embeddings_2d_DNABERT[i][1])\n",
    "    elif species_labels_dnabert2[i] == 3:\n",
    "        type3_x.append(all_embeddings_2d_DNABERT[i][0])\n",
    "        type3_y.append(all_embeddings_2d_DNABERT[i][1])\n",
    "    elif species_labels_dnabert2[i] == 4:\n",
    "        type4_x.append(all_embeddings_2d_DNABERT[i][0])\n",
    "        type4_y.append(all_embeddings_2d_DNABERT[i][1])\n",
    "\n",
    "type1 = axes1.scatter(type0_x, type0_y, s=30,alpha=.5, c='tab:red')\n",
    "type2 = axes1.scatter(type1_x, type1_y, s=30,alpha=.5, c='tab:green')\n",
    "type3 = axes1.scatter(type2_x, type2_y, s=30,alpha=.5, c='tab:blue')\n",
    "type4 = axes1.scatter(type3_x, type3_y, s=30,alpha=.5, c='tab:orange')\n",
    "type5 = axes1.scatter(type4_x, type4_y, s=30,alpha=.5, c='tab:purple')\n",
    "\n",
    "\n",
    "type0_x = []\n",
    "type0_y = []\n",
    "type1_x = []\n",
    "type1_y = []\n",
    "type2_x = []\n",
    "type2_y = []\n",
    "type3_x = []\n",
    "type3_y = []\n",
    "type4_x = []\n",
    "type4_y = []\n",
    "for i in range(len(species_labels_hyena)):\n",
    "    if species_labels_hyena[i] == 0:\n",
    "        type0_x.append(all_embeddings_2d_hyena[i][0])\n",
    "        type0_y.append(all_embeddings_2d_hyena[i][1])\n",
    "    elif species_labels_hyena[i] == 1:\n",
    "        type1_x.append(all_embeddings_2d_hyena[i][0])\n",
    "        type1_y.append(all_embeddings_2d_hyena[i][1])\n",
    "    elif species_labels_hyena[i] == 2:\n",
    "        type2_x.append(all_embeddings_2d_hyena[i][0])\n",
    "        type2_y.append(all_embeddings_2d_hyena[i][1])\n",
    "    elif species_labels_hyena[i] == 3:\n",
    "        type3_x.append(all_embeddings_2d_hyena[i][0])\n",
    "        type3_y.append(all_embeddings_2d_hyena[i][1])\n",
    "    elif species_labels_hyena[i] == 4:\n",
    "        type4_x.append(all_embeddings_2d_hyena[i][0])\n",
    "        type4_y.append(all_embeddings_2d_hyena[i][1])\n",
    "\n",
    "type1 = axes2.scatter(type0_x, type0_y, s=30,alpha=.5, c='tab:red')\n",
    "type2 = axes2.scatter(type1_x, type1_y, s=30,alpha=.5, c='tab:green')\n",
    "type3 = axes2.scatter(type2_x, type2_y, s=30,alpha=.5, c='tab:blue')\n",
    "type4 = axes2.scatter(type3_x, type3_y, s=30,alpha=.5, c='tab:orange')\n",
    "type5 = axes2.scatter(type4_x, type4_y, s=30,alpha=.5, c='tab:purple')\n",
    "\n",
    "\n",
    "type0_x = []\n",
    "type0_y = []\n",
    "type1_x = []\n",
    "type1_y = []\n",
    "type2_x = []\n",
    "type2_y = []\n",
    "type3_x = []\n",
    "type3_y = []\n",
    "type4_x = []\n",
    "type4_y = []\n",
    "for i in range(len(species_labels_genalm)):\n",
    "    if species_labels_genalm[i] == 0:\n",
    "        type0_x.append(all_embeddings_2d_gena[i][0])\n",
    "        type0_y.append(all_embeddings_2d_gena[i][1])\n",
    "    elif species_labels_genalm[i] == 1:\n",
    "        type1_x.append(all_embeddings_2d_gena[i][0])\n",
    "        type1_y.append(all_embeddings_2d_gena[i][1])\n",
    "    elif species_labels_genalm[i] == 2:\n",
    "        type2_x.append(all_embeddings_2d_gena[i][0])    \n",
    "        type2_y.append(all_embeddings_2d_gena[i][1])\n",
    "    elif species_labels_genalm[i] == 3:\n",
    "        type3_x.append(all_embeddings_2d_gena[i][0])\n",
    "        type3_y.append(all_embeddings_2d_gena[i][1])\n",
    "    elif species_labels_genalm[i] == 4:\n",
    "        type4_x.append(all_embeddings_2d_gena[i][0])\n",
    "        type4_y.append(all_embeddings_2d_gena[i][1])\n",
    "\n",
    "type1 = axes3.scatter(type0_x, type0_y, s=30,alpha=.5, c='tab:red')\n",
    "type2 = axes3.scatter(type1_x, type1_y, s=30,alpha=.5, c='tab:green')\n",
    "type3 = axes3.scatter(type2_x, type2_y, s=30,alpha=.5, c='tab:blue')\n",
    "type4 = axes3.scatter(type3_x, type3_y, s=30,alpha=.5, c='tab:orange')\n",
    "type5 = axes3.scatter(type4_x, type4_y, s=30,alpha=.5, c='tab:purple')\n",
    "\n",
    "\n",
    "type0_x = []\n",
    "type0_y = []\n",
    "type1_x = []\n",
    "type1_y = []\n",
    "type2_x = []\n",
    "type2_y = []\n",
    "type3_x = []\n",
    "type3_y = []\n",
    "type4_x = []\n",
    "type4_y = []\n",
    "for i in range(len(species_labels_NT)):\n",
    "    if species_labels_NT[i] == 0:\n",
    "        type0_x.append(all_embeddings_2d_NT[i][0])\n",
    "        type0_y.append(all_embeddings_2d_NT[i][1])\n",
    "    elif species_labels_NT[i] == 1:\n",
    "        type1_x.append(all_embeddings_2d_NT[i][0])\n",
    "        type1_y.append(all_embeddings_2d_NT[i][1])\n",
    "    elif species_labels_NT[i] == 2:\n",
    "        type2_x.append(all_embeddings_2d_NT[i][0])\n",
    "        type2_y.append(all_embeddings_2d_NT[i][1])\n",
    "    elif species_labels_NT[i] == 3:\n",
    "        type3_x.append(all_embeddings_2d_NT[i][0])\n",
    "        type3_y.append(all_embeddings_2d_NT[i][1])\n",
    "    elif species_labels_NT[i] == 4:\n",
    "        type4_x.append(all_embeddings_2d_NT[i][0])\n",
    "        type4_y.append(all_embeddings_2d_NT[i][1])\n",
    "\n",
    "type1 = axes4.scatter(type0_x, type0_y, s=30,alpha=.5, c='tab:red')\n",
    "type2 = axes4.scatter(type1_x, type1_y, s=30,alpha=.5, c='tab:green')\n",
    "type3 = axes4.scatter(type2_x, type2_y, s=30,alpha=.5, c='tab:blue')\n",
    "type4 = axes4.scatter(type3_x, type3_y, s=30,alpha=.5, c='tab:orange')\n",
    "type5 = axes4.scatter(type4_x, type4_y, s=30,alpha=.5, c='tab:purple')\n",
    "\n",
    "\n",
    "type0_x = []\n",
    "type0_y = []\n",
    "type1_x = []\n",
    "type1_y = []\n",
    "type2_x = []\n",
    "type2_y = []\n",
    "type3_x = []\n",
    "type3_y = []\n",
    "type4_x = []\n",
    "type4_y = []\n",
    "for i in range(len(species_labels_mamba)):\n",
    "    if species_labels_mamba[i] == 0:\n",
    "        type0_x.append(all_embeddings_2d_mamba[i][0])\n",
    "        type0_y.append(all_embeddings_2d_mamba[i][1])\n",
    "    \n",
    "    elif species_labels_mamba[i] == 1:\n",
    "        type1_x.append(all_embeddings_2d_mamba[i][0])\n",
    "        type1_y.append(all_embeddings_2d_mamba[i][1])\n",
    "    \n",
    "    elif species_labels_mamba[i] == 2:\n",
    "        type2_x.append(all_embeddings_2d_mamba[i][0])\n",
    "        type2_y.append(all_embeddings_2d_mamba[i][1])\n",
    "    \n",
    "    elif species_labels_mamba[i] == 3:\n",
    "        type3_x.append(all_embeddings_2d_mamba[i][0])\n",
    "        type3_y.append(all_embeddings_2d_mamba[i][1])\n",
    "    \n",
    "    elif species_labels_mamba[i] == 4:\n",
    "        type4_x.append(all_embeddings_2d_mamba[i][0])\n",
    "        type4_y.append(all_embeddings_2d_mamba[i][1])\n",
    "\n",
    "type1 = axes5.scatter(type0_x, type0_y, s=30,alpha=.5, c='tab:red')\n",
    "type2 = axes5.scatter(type1_x, type1_y, s=30,alpha=.5, c='tab:green')\n",
    "type3 = axes5.scatter(type2_x, type2_y, s=30,alpha=.5, c='tab:blue')\n",
    "type4 = axes5.scatter(type3_x, type3_y, s=30,alpha=.5, c='tab:orange')\n",
    "type5 = axes5.scatter(type4_x, type4_y, s=30,alpha=.5, c='tab:purple')\n",
    "    \n",
    "plt.suptitle('Sequence Embeddings, colored by species',fontsize=25,y=1.1,fontweight='bold')\n",
    "# plt.legend((type1, type2, type3, type4, type5), species, loc=\"lower center\")\n",
    "plt.legend((type1, type2, type3, type4, type5), species,ncol=5,\n",
    "                    loc=\"lower center\", title=\"species\",title_fontsize=20,\n",
    "                    bbox_to_anchor=(-1.7, -0.3),\n",
    "                    fancybox=True, shadow=True,\n",
    "                    fontsize=20)\n",
    "# plt.show()\n",
    "plt.savefig('sequence_embedding.pdf',bbox_inches = 'tight')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
