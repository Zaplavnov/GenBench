{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "dest_path='data/EMP'\n",
    "dataset_name='H3_txt'\n",
    "split='test'\n",
    "\n",
    "base_path = Path(dest_path) / dataset_name / split\n",
    "\n",
    "all_seqs = []\n",
    "all_labels = []\n",
    "label_mapper = {}\n",
    "\n",
    "for i, x in enumerate(base_path.iterdir()):\n",
    "    label_mapper[x.stem] = i\n",
    "\n",
    "for label_type in label_mapper.keys():\n",
    "    for path in (base_path / label_type).iterdir():\n",
    "        with open(path, \"r\") as f:\n",
    "            content = f.read()\n",
    "        all_seqs.append(content)\n",
    "        all_labels.append(label_mapper[label_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import autotokenizer\n",
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "max_length=128\n",
    "restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[..., -1:, :]          \n",
    "with torch.no_grad():\n",
    "    bert2_tokenizer=AutoTokenizer.from_pretrained(\"hyena-dna/weight/dnabert2\",trust_remote_code=True)\n",
    "    bert2_model=AutoModel.from_pretrained(\"hyena-dna/weight/dnabert2\",trust_remote_code=True).to('cuda')\n",
    "    full_sequence=[]\n",
    "    checkpoint=torch.load('hyena-dna/outputs/2024-05-05/09-15-14-919144/checkpoints/val/mcc.ckpt')['state_dict']\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.backbone.\"\n",
    "        )\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.output_transform.\"\n",
    "        )\n",
    "\n",
    "    bert2_decoder = nn.Linear(768,2).to('cuda')\n",
    "    #edit key name in hyena_decoder\n",
    "    state_dict=bert2_decoder.state_dict()\n",
    "    \n",
    "    bert2_model.load_state_dict(checkpoint,strict=False)\n",
    "    bert2_decoder.load_state_dict(checkpoint,strict=False)\n",
    "    bert2_model.eval()\n",
    "    bert2_decoder.eval()\n",
    "    out1_list=[]\n",
    "    label_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "        sequence_encoded=bert2_tokenizer(all_seqs[i],\n",
    "                            add_special_tokens= False,  # this is what controls adding eos\n",
    "                            padding=\"max_length\",\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                        )\n",
    "\n",
    "\n",
    "        sequence_tensor=torch.tensor(sequence_encoded['input_ids']).to('cuda')\n",
    "        sequence_tensor=torch.reshape(sequence_tensor,(1,max_length))\n",
    "        hidden_states=bert2_model(input_ids=sequence_tensor,export_hidden_states=True)[0]\n",
    "        hidden_states=restrict(hidden_states)\n",
    "        out1=bert2_decoder(hidden_states)\n",
    "        out1=torch.argmax(out1,dim=-1)\n",
    "        out1_list.append(out1.item())\n",
    "        label_list.append(all_labels[i])\n",
    "        print(mcc(out1_list,label_list))\n",
    "\n",
    "\n",
    "    #calculate the \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
