{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert2_path='outputs/2024-04-15/02-32-46-059563/checkpoints/val/genomic_structure_corr.ckpt'\n",
    "hyena_path='outputs/2024-04-15/08-34-24-880261/checkpoints/val/genomic_structure_corr.ckpt'\n",
    "orca_path='outputs/2024-04-15/09-19-56-380804/checkpoints/val/genomic_structure_corr.ckpt'\n",
    "mamba_path='outputs/2024-04-20/03-18-38-491508/checkpoints/val/genomic_structure_corr.ckpt'\n",
    "import sys\n",
    "\n",
    "from selene_utils2 import *\n",
    "from matplotlib import pyplot as plt\n",
    "batch_size=5\n",
    "max_length=6000\n",
    "dest_path='data/genomic_structure/resources/resources'\n",
    "t = Genomic2DFeatures(\n",
    "            [dest_path + \"/4DNFI9GMP2J8.rebinned.mcool::/resolutions/1000\"],\n",
    "            [\"r1000\"],\n",
    "            (int(max_length/1000), int(max_length/1000)),\n",
    "            cg=True,\n",
    "        )\n",
    "\n",
    "sampler = RandomPositionsSamplerHiC(\n",
    "            reference_sequence=MemmapGenome(\n",
    "                input_path=dest_path + \"/Homo_sapiens.GRCh38.dna.primary_assembly.fa\",\n",
    "                memmapfile=dest_path + \"/Homo_sapiens.GRCh38.dna.primary_assembly.fa.mmap\",\n",
    "                blacklist_regions=\"hg38\",\n",
    "            ),\n",
    "            target=t,\n",
    "            # target_1d=MultibinGenomicFeatures(\n",
    "            #     self.dest_path + \"/h1esc/h1esc.hg38.bed.sorted.gz\",\n",
    "            #     np.loadtxt(self.dest_path + \"/h1esc/h1esc.hg38.bed.sorted.features\", str),\n",
    "            #     1000,\n",
    "            #     1000,\n",
    "            #     (32, 10),\n",
    "            #     mode=\"any\",\n",
    "            # ),\n",
    "            features=[\"r1000\"],\n",
    "            test_holdout=[\"chr9\", \"chr10\"],\n",
    "            validation_holdout=[\"chr8\"],\n",
    "            sequence_length=6000,\n",
    "            position_resolution=1000,\n",
    "            random_shift=100,\n",
    "            random_strand=False,\n",
    "            cross_chromosome=False,\n",
    "        )\n",
    "sampler.mode = \"validate\"\n",
    "for i in range(10):\n",
    "    sampled_data = sampler.sample(batch_size=batch_size)\n",
    "\n",
    "    while np.isnan(sampled_data[1]).any():\n",
    "                sampled_data = sampler.sample(batch_size=batch_size)\n",
    "\n",
    "# print(sampled_data)\n",
    "plt.imshow(sampled_data[1][0, :, :],cmap = 'Spectral_r')   \n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence=sampled_data[0]\n",
    "target=sampled_data[1]\n",
    "target=torch.from_numpy(target).float().cuda()\n",
    "sequence_b=np.zeros((sequence.shape[0],sequence.shape[1]))\n",
    "mask=np.where(sequence==0.25)\n",
    "sequence_b=sequence.argmax(axis=2)\n",
    "sequence_b[[mask[0],mask[1]]]=4\n",
    "sequence=sequence_b\n",
    "map_to_genomic_sequence = {0: 'A', 1: 'C', 2: 'G', 3: 'T', 4: 'N'}\n",
    "#map sequence to genome \n",
    "sequence = \"\".join(map(lambda x: map_to_genomic_sequence[x], sequence.flatten().tolist()))\n",
    "#reshape list\n",
    "# sequence = np.array(list(sequence)).reshape(batch_size,-1)\n",
    "from scipy.stats import pearsonr\n",
    "def genomic_structure_corr(logit,y,ignore_index=-100):\n",
    "\n",
    "\n",
    "    pred=logit\n",
    "    target=y\n",
    "    normmat_bydist = np.exp(\n",
    "        np.load(\"orca/resources/resources/4DNFI643OYP9.rebinned.mcool.expected.res1000.npy\")        \n",
    "\n",
    "    )[:10]\n",
    "    normmat = normmat_bydist[np.abs(np.arange(6)[:, None] - np.arange(6)[None, :])]\n",
    "    normmat_r = torch.from_numpy(normmat).float().cuda()\n",
    "    eps = torch.min(normmat_r)\n",
    "    target = torch.log(((target + eps) / (normmat_r + eps)))\n",
    "    corr=[]\n",
    "    #convert to numpy\n",
    "    target=target.cpu().numpy().reshape((pred.shape[0], -1))\n",
    "    pred=pred.detach().cpu().numpy().reshape((pred.shape[0], -1))\n",
    "    for j in range(pred.shape[0]):\n",
    "            if np.mean(np.isnan(target[j, :])) < 0.7:\n",
    "                corr.append(\n",
    "                    pearsonr(\n",
    "                        pred[j, ~np.isnan(target[j, :])],\n",
    "                        target[j, ~np.isnan(target[j, :])],\n",
    "                    )[0]\n",
    "                )\n",
    "            else:\n",
    "                corr.append(np.nan)\n",
    "    corr=np.nanmean(corr)\n",
    "    return corr\n",
    "def genomic_structure_mse(logit,y,ignore_index=-100):\n",
    "\n",
    "    pred=logit\n",
    "    target=y\n",
    "    if torch.isnan(target).all():\n",
    "        target=torch.rand_like(target)\n",
    "\n",
    "    normmat_bydist = np.exp(\n",
    "        np.load(\"orca/resources/resources/4DNFI643OYP9.rebinned.mcool.expected.res1000.npy\")\n",
    "\n",
    "    )[:8]\n",
    "    normmat = normmat_bydist[np.abs(np.arange(6)[:, None] - np.arange(6)[None, :])]\n",
    "    normmat_r = torch.from_numpy(normmat).float().cuda()\n",
    "    eps = torch.min(normmat_r)\n",
    "    target = torch.nanmean(\n",
    "                torch.nanmean(torch.reshape(target, (target.shape[0], 6, 1, 6, 1)), axis=4),\n",
    "                axis=2,\n",
    "            )\n",
    "    target_r = torch.log(((target + eps) / (normmat_r + eps)))\n",
    "    target_cuda = target_r\n",
    "\n",
    "    loss = (\n",
    "        (\n",
    "            pred[~torch.isnan(target)]\n",
    "            - target_cuda[~torch.isnan(target)]\n",
    "        )\n",
    "        ** 2\n",
    "    ).mean()\n",
    "\n",
    "\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import autotokenizer\n",
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "with torch.no_grad():\n",
    "    hyena_tokenizer=AutoTokenizer.from_pretrained(\"weight/hyenadna/hyenadna-large-1m-seqlen\",trust_remote_code=True)\n",
    "    hyena_model=AutoModel.from_pretrained(\"weight/hyenadna/hyenadna-large-1m-seqlen\",trust_remote_code=True).to('cuda')\n",
    "    full_sequence=[]\n",
    "    checkpoint=torch.load('outputs/2024-04-14/01-11-41-629746/checkpoints/last.ckpt')['state_dict']\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.backbone.\"\n",
    "        )\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.length_transform_2.\"\n",
    "        )\n",
    "\n",
    "    hyena_decoder = nn.Linear(6000,36,bias=False).to('cuda')\n",
    "    #edit key name in hyena_decoder\n",
    "    state_dict=hyena_decoder.state_dict()\n",
    "    \n",
    "    hyena_model.load_state_dict(checkpoint,strict=False)\n",
    "    hyena_decoder.load_state_dict(checkpoint,strict=False)\n",
    "    hyena_model.eval()\n",
    "    hyena_decoder.eval()\n",
    "\n",
    "    sequence_encoded=hyena_tokenizer(sequence,\n",
    "                        add_special_tokens= False,  # this is what controls adding eos\n",
    "                        padding=\"max_length\",\n",
    "                        max_length=max_length*batch_size,\n",
    "                        truncation=True,\n",
    "                    )\n",
    "\n",
    "\n",
    "    sequence_tensor=torch.tensor(sequence_encoded['input_ids']).to('cuda')\n",
    "    sequence_tensor=torch.reshape(sequence_tensor,(batch_size,max_length))\n",
    "    hidden_states=hyena_model(sequence_tensor)['last_hidden_state']\n",
    "    output=hidden_states[..., -6000:, :]\n",
    "    out1 = output[:,:,0]\n",
    "    out1=hyena_decoder(out1)\n",
    "    out1=out1.reshape(out1.shape[0],6,6)\n",
    "    mat_hyena=out1+out1.transpose(1,2)\n",
    "\n",
    "    #calculate the \n",
    "    corr=genomic_structure_corr(mat_hyena,target)\n",
    "    print(corr)\n",
    "    mse=genomic_structure_mse(mat_hyena,target)\n",
    "    print(mse)\n",
    "from matplotlib import pyplot as plt\n",
    "def figshow(x, np=False):\n",
    "        if np:\n",
    "            plt.imshow(x.squeeze())\n",
    "        else:\n",
    "            plt.imshow(x.squeeze().cpu().detach().numpy())\n",
    "        #remove boudary\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "#plot the target and predicted genomic structure\n",
    "# figure,(axes1, axes2, axes3, axes4, axes5)=plt.subplots(1, 5,figsize=(20,5))\n",
    "# axes1.imshow(target[0].squeeze().cpu().detach().numpy())\n",
    "# axes1.axis('off')\n",
    "# axes1\n",
    "\n",
    "plt.imshow(mat_hyena[0].cpu().detach().numpy(),cmap = 'Spectral_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "with torch.no_grad():\n",
    "    state_dict='weight/dnabert2'\n",
    "    bert2_tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "    bert2_model=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "    full_sequence=[]\n",
    "    checkpoint=torch.load('outputs/2024-04-15/02-32-46-059563/checkpoints/last.ckpt')['state_dict']\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.backbone.\"\n",
    "        )\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.length_transform_2.\"\n",
    "        )\n",
    "\n",
    "    bert2_decoder = nn.Linear(6000,36,bias=False).to('cuda')\n",
    "    #edit key name in hyena_decoder\n",
    "    \n",
    "    bert2_model.load_state_dict(checkpoint,strict=False)\n",
    "    bert2_decoder.load_state_dict(checkpoint,strict=False)\n",
    "    bert2_model.eval()\n",
    "    bert2_decoder.eval()\n",
    "\n",
    "    sequence_encoded=bert2_tokenizer(sequence,\n",
    "                        add_special_tokens= False,  # this is what controls adding eos\n",
    "                        padding=\"max_length\",\n",
    "                        max_length=max_length*batch_size,\n",
    "                        truncation=True,\n",
    "                    )\n",
    "\n",
    "\n",
    "    sequence_tensor=torch.tensor(sequence_encoded['input_ids']).to('cuda')\n",
    "    sequence_tensor=torch.reshape(sequence_tensor,(batch_size,max_length))\n",
    "    hidden_states=bert2_model(input_ids=sequence_tensor,output_hidden_states=True,)[0]\n",
    "    output=hidden_states[..., -6000:, :]\n",
    "    out1 = output[:,:,0]\n",
    "    out1=bert2_decoder(out1)\n",
    "    out1=out1.reshape(out1.shape[0],6,6)\n",
    "    mat_bert2=out1+out1.transpose(1,2)\n",
    "\n",
    "    #calculate the \n",
    "    corr=genomic_structure_corr(mat_bert2,target)\n",
    "    print(corr)\n",
    "    mse=genomic_structure_mse(mat_bert2,target)\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "with torch.no_grad():\n",
    "    state_dict='weight/mamba'\n",
    "    mamba_tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "    mamba_model=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "    full_sequence=[]\n",
    "    checkpoint=torch.load('outputs/2024-04-20/03-18-38-491508/checkpoints/last.ckpt')['state_dict']\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.backbone.\"\n",
    "        )\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.length_transform_2.\"\n",
    "        )\n",
    "\n",
    "    mamba_decoder = nn.Linear(6000,36,bias=False).to('cuda')\n",
    "    #edit key name in hyena_decoder\n",
    "    \n",
    "    mamba_model.load_state_dict(checkpoint,strict=False)\n",
    "    mamba_decoder.load_state_dict(checkpoint,strict=False)\n",
    "    mamba_model.eval()\n",
    "    mamba_decoder.eval()\n",
    "\n",
    "    sequence_encoded=mamba_tokenizer(sequence,\n",
    "                        add_special_tokens= False,  # this is what controls adding eos\n",
    "                        padding=\"max_length\",\n",
    "                        max_length=max_length*batch_size,\n",
    "                        truncation=True,\n",
    "                    )\n",
    "\n",
    "\n",
    "    sequence_tensor=torch.tensor(sequence_encoded['input_ids']).to('cuda')\n",
    "    sequence_tensor=torch.reshape(sequence_tensor,(batch_size,max_length))\n",
    "    hidden_states=mamba_model(input_ids=sequence_tensor,output_hidden_states=True,)[0]\n",
    "    output=hidden_states[..., -6000:, :]\n",
    "    out1 = output[:,:,0]\n",
    "    out1=mamba_decoder(out1)\n",
    "    out1=out1.reshape(out1.shape[0],6,6)\n",
    "    mat_mamba=out1+out1.transpose(1,2)\n",
    "\n",
    "    #calculate the \n",
    "    corr=genomic_structure_corr(mat_mamba,target)\n",
    "    print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from src.models.sequence.orca import Orca\n",
    "orca_model=Orca().to('cuda')\n",
    "seq_ids =torch.from_numpy(sampled_data[0]).squeeze(0)\n",
    "seq_ids = seq_ids.float().to('cuda')\n",
    "target = torch.from_numpy(sampled_data[1]).squeeze(0)\n",
    "target = target.float().to('cuda')\n",
    "parameter=torch.load('outputs/2024-04-15/09-19-56-380804/checkpoints/last.ckpt')['state_dict']\n",
    "checkpoint=torch.load('outputs/2024-04-15/09-19-56-380804/checkpoints/last.ckpt')['state_dict']\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.backbone.\"\n",
    "        )\n",
    "torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.length_transform_2.\"\n",
    "        )\n",
    "orca_model.load_state_dict(checkpoint,strict=False)\n",
    "out_orca=orca_model(seq_ids)[0]\n",
    "corr=genomic_structure_corr(out_orca,target)\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot nxn image\n",
    "rows = ['GT','Orca','Caduceus','Hyena-DNA','DNABERT2']\n",
    "out_collection=[]\n",
    "normmat_bydist = np.exp(\n",
    "                np.load(\"orca/resources/resources/4DNFI643OYP9.rebinned.mcool.expected.res1000.npy\")\n",
    "            )[:6]\n",
    "normmat = normmat_bydist[np.abs(np.arange(6)[:, None] - np.arange(6)[None, :])]\n",
    "normmat_r = torch.from_numpy(normmat).float().cuda()\n",
    "eps = torch.min(normmat_r)\n",
    "target_r=torch.log(((target + eps) / (normmat_r + eps)))\n",
    "out_collection.append(target_r.cpu().detach().numpy())\n",
    "out_collection.append(out_orca.cpu().detach().numpy())\n",
    "out_collection.append(mat_mamba.cpu().detach().numpy())\n",
    "out_collection.append(mat_hyena.cpu().detach().numpy())\n",
    "out_collection.append(mat_bert2.cpu().detach().numpy())\n",
    "_min, _max = np.amin(out_collection), np.amax(out_collection)\n",
    "fig,axes = plt.subplots(5,5)\n",
    "for ax, row in zip(axes[:,0], rows):\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.yaxis.set_label_position('left')\n",
    "    ax2.spines['left'].set_visible(False)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.spines['bottom'].set_visible(False)\n",
    "    #set ticks invisible\n",
    "    ax2.tick_params(axis='both', which='both', length=0)\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_ylabel(row, rotation=0, size='large',\n",
    "                   ha='right', va='center')\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        ax_n=axes[i,j].imshow(out_collection[i][j], vmin = _min, vmax = _max)\n",
    "        axes[i,j].axis('off')\n",
    "        axes[i,j].autoscale(False)\n",
    "fig.colorbar(ax_n,ax=axes,orientation='vertical')\n",
    "\n",
    "plt.suptitle('Genomic Structure Prediction',fontsize=15,y=0.95,fontweight='bold')\n",
    "plt.show()\n",
    "        #show value bar\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
